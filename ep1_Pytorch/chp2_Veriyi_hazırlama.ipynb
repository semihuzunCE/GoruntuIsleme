{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from skimage import io\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriyi Dahil Etme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class veri(Dataset): #dataset classı pytorch un veriyi eklemek için kullandırttığı bir classdır.\n",
    "    def __init__(self, csv_file, root_dir, transform=None): #csv_file fotograflarımızın adreslerinin yer aldığı dosyadır onun pathini vermemiz gerekiyor. root_dir fotograflarımızın oldugu klasörün adresidir\n",
    "        self.annotations=pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    def __getitem__(self, index):\n",
    "       img_path=os.path.join(self.root_dir,self.annotations.iloc[index,0])\n",
    "       image=io.imread(img_path)\n",
    "       y_label=torch.tensor(int(self.annotations.iloc[index,1]))\n",
    "       \n",
    "       if self.transform:\n",
    "              image=self.transform(image)\n",
    "              return (image,y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriyi Hazırlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=veri(csv_file=\"D:\\\\udemy_data\\\\f1_classification\\\\f111.csv\",root_dir=\"D:\\\\udemy_data\\\\f1_classification\",\n",
    "transform=torchvision.transforms.Compose([ #compose metodu birden fazla transform işlemini tek seferde yapmamıza olanak tanır.\n",
    "    transforms.ToTensor(), #tensore cevirmemizi sağlar verimizi\n",
    "    transforms.Resize(size=(28,28)),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,test_set=torch.utils.data.random_split(dataset,[200,79]) # verimizin 200 ü train geri kalan 79 tanesi test için ayrıldı\n",
    "train_loader=DataLoader(dataset=train_set,batch_size=1,shuffle=False)\n",
    "test_loader=DataLoader(dataset=test_set,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriyi Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mercedes\n",
      "torch.Size([1, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "batch_size=1\n",
    "classes=[\"Ferrari\",\"Mclaren\",\"Mercedes\",\"Redbull\"]\n",
    "\n",
    "def imshow(img):\n",
    "    img=img/2+0.5\n",
    "    npimg=img.numpy()\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.show()\n",
    "dataiter=iter(train_loader)\n",
    "images,labels=dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(\"\".join('%5s' % classes[labels[j]] for j in range(batch_size)))\n",
    "print(images.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Mimarisini Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): #model yapısı class içinde oluşturulur ilk 3 satır pytochda class için temel tanımlamalardır.\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        #conv katmanları:\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=4,kernel_size=(5,5)) #giriş kanalı, çıkış kanalı ve kernel size ı tanımladık atride(adım) gibi tanımlamaları default değerde bıraktık.\n",
    "        self.conv2=nn.Conv2d(in_channels=4,out_channels=8,kernel_size=(3,3))\n",
    "        self.conv3=nn.Conv2d(in_channels=8,out_channels=16,kernel_size=(2,2))\n",
    "        self.conv4=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=(2,2))\n",
    "        #max pooling katmanı:\n",
    "\n",
    "        self.max=nn.MaxPool2d(kernel_size=(2,2)) # bu katman her conv dan sonra çalışıcak bağlama kısmında belirtiyoruz. Buraya birden fazla maxpool fonksiyonu tanımlayıp bağlama fonksiyonunda onlarıda kullanabiliriz.\n",
    "\n",
    "        #aktivasyon fonksiyonu:\n",
    "        self.func=nn.ELU()\n",
    "\n",
    "        #fully connected laerımız: (\"tensorflowda dense diye geçiyor\")\n",
    "        self.fc1=nn.Linear(in_features=32,out_features=50) #conv katmanından en son 32 kanal çıktıgı için girişi 32 ile başlattık.\n",
    "        self.fc2=nn.Linear(in_features=50,out_features=50)\n",
    "        self.fc3=nn.Linear(in_features=50,out_features=100)\n",
    "        self.fc4=nn.Linear(in_features=100,out_features=4) # son çıktı katmanımız 4 formula aracı oldugu için 4 çıkışlı yaptık.\n",
    "\n",
    "    def forward(self,x): # bu fonksiyon bağlama fonksiyonudur oluşturdugumuz katmanlar birbirine bağlı değil bu fonksiyon ile bağlama işlmeini geçekleştiriyoruz.\n",
    "         x=self.conv1(x) #conv katmanının çıkışını aktivasyon fonksiyonuna onuda maxpool a gönderiyoruz sonuncu conv katmanının çıkışında maxpool yok\n",
    "         x=self.func(x)\n",
    "         x=self.max(x)\n",
    "\n",
    "         x=self.conv2(x)\n",
    "         x=self.func(x)\n",
    "         x=self.max(x)\n",
    "\n",
    "         x=self.conv3(x)\n",
    "         x=self.func(x)\n",
    "         x=self.max(x)\n",
    "\n",
    "         x=self.conv4(x)\n",
    "         x=self.func(x)\n",
    "\n",
    "         x=x.view(x.size(0),-1) #flatten: düzleştirme işlemi\n",
    "\n",
    "         x=self.fc1(x)\n",
    "         x=self.func(x)\n",
    "         x=self.fc2(x)\n",
    "         x=self.func(x)\n",
    "         x=self.fc3(x)\n",
    "         x=self.func(x)\n",
    "         x=self.fc4(x)\n",
    "            \n",
    "         return x\n",
    "          \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin Eğitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1],loss:1.3900\n",
      "Epoch [1/2],loss:1.3586\n",
      "Epoch [1/3],loss:1.3395\n",
      "Epoch [1/4],loss:1.3723\n",
      "Epoch [1/5],loss:1.3047\n",
      "Epoch [1/6],loss:1.2818\n",
      "Epoch [1/7],loss:1.2656\n",
      "Epoch [1/8],loss:1.3272\n",
      "Epoch [1/9],loss:1.3291\n",
      "Epoch [1/10],loss:1.2065\n",
      "Epoch [1/11],loss:1.1904\n",
      "Epoch [1/12],loss:1.7558\n",
      "Epoch [1/13],loss:1.7496\n",
      "Epoch [1/14],loss:1.1531\n",
      "Epoch [1/15],loss:1.7507\n",
      "Epoch [1/16],loss:1.4295\n",
      "Epoch [1/17],loss:1.7480\n",
      "Epoch [1/18],loss:1.7340\n",
      "Epoch [1/19],loss:1.4423\n",
      "Epoch [1/20],loss:1.4361\n",
      "Epoch [1/21],loss:1.6865\n",
      "Epoch [1/22],loss:1.6738\n",
      "Epoch [1/23],loss:1.3759\n",
      "Epoch [1/24],loss:1.4190\n",
      "Epoch [1/25],loss:1.4201\n",
      "Epoch [1/26],loss:1.3864\n",
      "Epoch [1/27],loss:1.6165\n",
      "Epoch [1/28],loss:1.1918\n",
      "Epoch [1/29],loss:1.3953\n",
      "Epoch [1/30],loss:1.3947\n",
      "Epoch [1/31],loss:1.2058\n",
      "Epoch [1/32],loss:1.2108\n",
      "Epoch [1/33],loss:1.3937\n",
      "Epoch [1/34],loss:1.5784\n",
      "Epoch [1/35],loss:1.2128\n",
      "Epoch [1/36],loss:1.5791\n",
      "Epoch [1/37],loss:1.5659\n",
      "Epoch [1/38],loss:1.4104\n",
      "Epoch [1/39],loss:1.5627\n",
      "Epoch [1/40],loss:1.2239\n",
      "Epoch [1/41],loss:1.5480\n",
      "Epoch [1/42],loss:1.2246\n",
      "Epoch [1/43],loss:1.2224\n",
      "Epoch [1/44],loss:1.2192\n",
      "Epoch [1/45],loss:1.2115\n",
      "Epoch [1/46],loss:1.4043\n",
      "Epoch [1/47],loss:1.5161\n",
      "Epoch [1/48],loss:1.4484\n",
      "Epoch [1/49],loss:1.5143\n",
      "Epoch [1/50],loss:1.4551\n",
      "Epoch [1/51],loss:1.4525\n",
      "Epoch [1/52],loss:1.4340\n",
      "Epoch [1/53],loss:1.4474\n",
      "Epoch [1/54],loss:1.4959\n",
      "Epoch [1/55],loss:1.4887\n",
      "Epoch [1/56],loss:1.4373\n",
      "Epoch [1/57],loss:1.4790\n",
      "Epoch [1/58],loss:1.4743\n",
      "Epoch [1/59],loss:1.4275\n",
      "Epoch [1/60],loss:1.2305\n",
      "Epoch [1/61],loss:1.4143\n",
      "Epoch [1/62],loss:1.4552\n",
      "Epoch [1/63],loss:1.4062\n",
      "Epoch [1/64],loss:1.4412\n",
      "Epoch [1/65],loss:1.4366\n",
      "Epoch [1/66],loss:1.3933\n",
      "Epoch [1/67],loss:1.4705\n",
      "Epoch [1/68],loss:1.3770\n",
      "Epoch [1/69],loss:1.4120\n",
      "Epoch [1/70],loss:1.2977\n",
      "Epoch [1/71],loss:1.2957\n",
      "Epoch [1/72],loss:1.4043\n",
      "Epoch [1/73],loss:1.4002\n",
      "Epoch [1/74],loss:1.3575\n",
      "Epoch [1/75],loss:1.3065\n",
      "Epoch [1/76],loss:1.5000\n",
      "Epoch [1/77],loss:1.3801\n",
      "Epoch [1/78],loss:1.3522\n",
      "Epoch [1/79],loss:1.5115\n",
      "Epoch [1/80],loss:1.3169\n",
      "Epoch [1/81],loss:1.3190\n",
      "Epoch [1/82],loss:1.5106\n",
      "Epoch [1/83],loss:1.3157\n",
      "Epoch [1/84],loss:1.3538\n",
      "Epoch [1/85],loss:1.3142\n",
      "Epoch [1/86],loss:1.5094\n",
      "Epoch [1/87],loss:1.2995\n",
      "Epoch [1/88],loss:1.3851\n",
      "Epoch [1/89],loss:1.2948\n",
      "Epoch [1/90],loss:1.3878\n",
      "Epoch [1/91],loss:1.5064\n",
      "Epoch [1/92],loss:1.3884\n",
      "Epoch [1/93],loss:1.2784\n",
      "Epoch [1/94],loss:1.5027\n",
      "Epoch [1/95],loss:1.3934\n",
      "Epoch [1/96],loss:1.3800\n",
      "Epoch [1/97],loss:1.3965\n",
      "Epoch [1/98],loss:1.3949\n",
      "Epoch [1/99],loss:1.2704\n",
      "Epoch [1/100],loss:1.5125\n",
      "Epoch [1/101],loss:1.2678\n",
      "Epoch [1/102],loss:1.5013\n",
      "Epoch [1/103],loss:1.4994\n",
      "Epoch [1/104],loss:1.3979\n",
      "Epoch [1/105],loss:1.3922\n",
      "Epoch [1/106],loss:1.4024\n",
      "Epoch [1/107],loss:1.4014\n",
      "Epoch [1/108],loss:1.3942\n",
      "Epoch [1/109],loss:1.4916\n",
      "Epoch [1/110],loss:1.2702\n",
      "Epoch [1/111],loss:1.4740\n",
      "Epoch [1/112],loss:1.3852\n",
      "Epoch [1/113],loss:1.3953\n",
      "Epoch [1/114],loss:1.4708\n",
      "Epoch [1/115],loss:1.3872\n",
      "Epoch [1/116],loss:1.3085\n",
      "Epoch [1/117],loss:1.4739\n",
      "Epoch [1/118],loss:1.4010\n",
      "Epoch [1/119],loss:1.2938\n",
      "Epoch [1/120],loss:1.3001\n",
      "Epoch [1/121],loss:1.4566\n",
      "Epoch [1/122],loss:1.3838\n",
      "Epoch [1/123],loss:1.3833\n",
      "Epoch [1/124],loss:1.4560\n",
      "Epoch [1/125],loss:1.3874\n",
      "Epoch [1/126],loss:1.4300\n",
      "Epoch [1/127],loss:1.4414\n",
      "Epoch [1/128],loss:1.4149\n",
      "Epoch [1/129],loss:1.3726\n",
      "Epoch [1/130],loss:1.4188\n",
      "Epoch [1/131],loss:1.4312\n",
      "Epoch [1/132],loss:1.4234\n",
      "Epoch [1/133],loss:1.4230\n",
      "Epoch [1/134],loss:1.4375\n",
      "Epoch [1/135],loss:1.4209\n",
      "Epoch [1/136],loss:1.3739\n",
      "Epoch [1/137],loss:1.3447\n",
      "Epoch [1/138],loss:1.3952\n",
      "Epoch [1/139],loss:1.3676\n",
      "Epoch [1/140],loss:1.3709\n",
      "Epoch [1/141],loss:1.3653\n",
      "Epoch [1/142],loss:1.3923\n",
      "Epoch [1/143],loss:1.4010\n",
      "Epoch [1/144],loss:1.3556\n",
      "Epoch [1/145],loss:1.3683\n",
      "Epoch [1/146],loss:1.3622\n",
      "Epoch [1/147],loss:1.3473\n",
      "Epoch [1/148],loss:1.4130\n",
      "Epoch [1/149],loss:1.3809\n",
      "Epoch [1/150],loss:1.3298\n",
      "Epoch [1/151],loss:1.3548\n",
      "Epoch [1/152],loss:1.3210\n",
      "Epoch [1/153],loss:1.4308\n",
      "Epoch [1/154],loss:1.3154\n",
      "Epoch [1/155],loss:1.3841\n",
      "Epoch [1/156],loss:1.4244\n",
      "Epoch [1/157],loss:1.4469\n",
      "Epoch [1/158],loss:1.3722\n",
      "Epoch [1/159],loss:1.3090\n",
      "Epoch [1/160],loss:1.2739\n",
      "Epoch [1/161],loss:1.4372\n",
      "Epoch [1/162],loss:1.4439\n",
      "Epoch [1/163],loss:1.4443\n",
      "Epoch [1/164],loss:1.4442\n",
      "Epoch [1/165],loss:1.4438\n",
      "Epoch [1/166],loss:1.3436\n",
      "Epoch [1/167],loss:1.4133\n",
      "Epoch [1/168],loss:1.4355\n",
      "Epoch [1/169],loss:1.4485\n",
      "Epoch [1/170],loss:1.4266\n",
      "Epoch [1/171],loss:1.4418\n",
      "Epoch [1/172],loss:1.3421\n",
      "Epoch [1/173],loss:1.4149\n",
      "Epoch [1/174],loss:1.4368\n",
      "Epoch [1/175],loss:1.3295\n",
      "Epoch [1/176],loss:1.3143\n",
      "Epoch [1/177],loss:1.4161\n",
      "Epoch [1/178],loss:1.4137\n",
      "Epoch [1/179],loss:1.4138\n",
      "Epoch [1/180],loss:1.4302\n",
      "Epoch [1/181],loss:1.4136\n",
      "Epoch [1/182],loss:1.4198\n",
      "Epoch [1/183],loss:1.4348\n",
      "Epoch [1/184],loss:1.3475\n",
      "Epoch [1/185],loss:1.3915\n",
      "Epoch [1/186],loss:1.3972\n",
      "Epoch [1/187],loss:1.3797\n",
      "Epoch [1/188],loss:1.3920\n",
      "Epoch [1/189],loss:1.3572\n",
      "Epoch [1/190],loss:1.3855\n",
      "Epoch [1/191],loss:1.4100\n",
      "Epoch [1/192],loss:1.3970\n",
      "Epoch [1/193],loss:1.3864\n",
      "Epoch [1/194],loss:1.3739\n",
      "Epoch [1/195],loss:1.3759\n",
      "Epoch [1/196],loss:1.3699\n",
      "Epoch [1/197],loss:1.3749\n",
      "Epoch [1/198],loss:1.3612\n",
      "Epoch [1/199],loss:1.3544\n",
      "Epoch [1/200],loss:1.3599\n",
      "Epoch [2/1],loss:1.3574\n",
      "Epoch [2/2],loss:1.4104\n",
      "Epoch [2/3],loss:1.4253\n",
      "Epoch [2/4],loss:1.3330\n",
      "Epoch [2/5],loss:1.3816\n",
      "Epoch [2/6],loss:1.3657\n",
      "Epoch [2/7],loss:1.4266\n",
      "Epoch [2/8],loss:1.3693\n",
      "Epoch [2/9],loss:1.3630\n",
      "Epoch [2/10],loss:1.3475\n",
      "Epoch [2/11],loss:1.3431\n",
      "Epoch [2/12],loss:1.4993\n",
      "Epoch [2/13],loss:1.4588\n",
      "Epoch [2/14],loss:1.3247\n",
      "Epoch [2/15],loss:1.4431\n",
      "Epoch [2/16],loss:1.3209\n",
      "Epoch [2/17],loss:1.5296\n",
      "Epoch [2/18],loss:1.4808\n",
      "Epoch [2/19],loss:1.3324\n",
      "Epoch [2/20],loss:1.3395\n",
      "Epoch [2/21],loss:1.4339\n",
      "Epoch [2/22],loss:1.5274\n",
      "Epoch [2/23],loss:1.3745\n",
      "Epoch [2/24],loss:1.3124\n",
      "Epoch [2/25],loss:1.3327\n",
      "Epoch [2/26],loss:1.4227\n",
      "Epoch [2/27],loss:1.4599\n",
      "Epoch [2/28],loss:1.2871\n",
      "Epoch [2/29],loss:1.3042\n",
      "Epoch [2/30],loss:1.3847\n",
      "Epoch [2/31],loss:1.2699\n",
      "Epoch [2/32],loss:1.2847\n",
      "Epoch [2/33],loss:1.3341\n",
      "Epoch [2/34],loss:1.4452\n",
      "Epoch [2/35],loss:1.2615\n",
      "Epoch [2/36],loss:1.4744\n",
      "Epoch [2/37],loss:1.4057\n",
      "Epoch [2/38],loss:1.4310\n",
      "Epoch [2/39],loss:1.3988\n",
      "Epoch [2/40],loss:1.3805\n",
      "Epoch [2/41],loss:1.3872\n",
      "Epoch [2/42],loss:1.3757\n",
      "Epoch [2/43],loss:1.2823\n",
      "Epoch [2/44],loss:1.3449\n",
      "Epoch [2/45],loss:1.2490\n",
      "Epoch [2/46],loss:1.3107\n",
      "Epoch [2/47],loss:1.3885\n",
      "Epoch [2/48],loss:1.4413\n",
      "Epoch [2/49],loss:1.3276\n",
      "Epoch [2/50],loss:1.4569\n",
      "Epoch [2/51],loss:1.4484\n",
      "Epoch [2/52],loss:1.3966\n",
      "Epoch [2/53],loss:1.4180\n",
      "Epoch [2/54],loss:1.4115\n",
      "Epoch [2/55],loss:1.4406\n",
      "Epoch [2/56],loss:1.4344\n",
      "Epoch [2/57],loss:1.3662\n",
      "Epoch [2/58],loss:1.3107\n",
      "Epoch [2/59],loss:1.4584\n",
      "Epoch [2/60],loss:1.1851\n",
      "Epoch [2/61],loss:1.4076\n",
      "Epoch [2/62],loss:1.3412\n",
      "Epoch [2/63],loss:1.4106\n",
      "Epoch [2/64],loss:1.3929\n",
      "Epoch [2/65],loss:1.4161\n",
      "Epoch [2/66],loss:1.4274\n",
      "Epoch [2/67],loss:1.3746\n",
      "Epoch [2/68],loss:1.3971\n",
      "Epoch [2/69],loss:1.2879\n",
      "Epoch [2/70],loss:1.6346\n",
      "Epoch [2/71],loss:1.3388\n",
      "Epoch [2/72],loss:1.1373\n",
      "Epoch [2/73],loss:1.2332\n",
      "Epoch [2/74],loss:1.3796\n",
      "Epoch [2/75],loss:1.3431\n",
      "Epoch [2/76],loss:1.3770\n",
      "Epoch [2/77],loss:1.2960\n",
      "Epoch [2/78],loss:1.3586\n",
      "Epoch [2/79],loss:1.3823\n",
      "Epoch [2/80],loss:1.4192\n",
      "Epoch [2/81],loss:1.2714\n",
      "Epoch [2/82],loss:1.4043\n",
      "Epoch [2/83],loss:1.2534\n",
      "Epoch [2/84],loss:1.3513\n",
      "Epoch [2/85],loss:1.4660\n",
      "Epoch [2/86],loss:1.3845\n",
      "Epoch [2/87],loss:1.1413\n",
      "Epoch [2/88],loss:1.0482\n",
      "Epoch [2/89],loss:1.1955\n",
      "Epoch [2/90],loss:1.1380\n",
      "Epoch [2/91],loss:1.4224\n",
      "Epoch [2/92],loss:1.3288\n",
      "Epoch [2/93],loss:1.5539\n",
      "Epoch [2/94],loss:1.3686\n",
      "Epoch [2/95],loss:1.3931\n",
      "Epoch [2/96],loss:1.0093\n",
      "Epoch [2/97],loss:1.4048\n",
      "Epoch [2/98],loss:1.4392\n",
      "Epoch [2/99],loss:0.9594\n",
      "Epoch [2/100],loss:1.5046\n",
      "Epoch [2/101],loss:1.0740\n",
      "Epoch [2/102],loss:1.4199\n",
      "Epoch [2/103],loss:1.3691\n",
      "Epoch [2/104],loss:1.6255\n",
      "Epoch [2/105],loss:1.3711\n",
      "Epoch [2/106],loss:1.4489\n",
      "Epoch [2/107],loss:1.6336\n",
      "Epoch [2/108],loss:1.1095\n",
      "Epoch [2/109],loss:1.5520\n",
      "Epoch [2/110],loss:0.9353\n",
      "Epoch [2/111],loss:1.3298\n",
      "Epoch [2/112],loss:1.0452\n",
      "Epoch [2/113],loss:1.3959\n",
      "Epoch [2/114],loss:1.3952\n",
      "Epoch [2/115],loss:1.1036\n",
      "Epoch [2/116],loss:1.7962\n",
      "Epoch [2/117],loss:1.5543\n",
      "Epoch [2/118],loss:1.4057\n",
      "Epoch [2/119],loss:0.9870\n",
      "Epoch [2/120],loss:0.9758\n",
      "Epoch [2/121],loss:1.3350\n",
      "Epoch [2/122],loss:1.3356\n",
      "Epoch [2/123],loss:1.0770\n",
      "Epoch [2/124],loss:1.5513\n",
      "Epoch [2/125],loss:1.4884\n",
      "Epoch [2/126],loss:1.3288\n",
      "Epoch [2/127],loss:1.4130\n",
      "Epoch [2/128],loss:1.3684\n",
      "Epoch [2/129],loss:1.4217\n",
      "Epoch [2/130],loss:1.3187\n",
      "Epoch [2/131],loss:1.4620\n",
      "Epoch [2/132],loss:1.5102\n",
      "Epoch [2/133],loss:1.3384\n",
      "Epoch [2/134],loss:1.4342\n",
      "Epoch [2/135],loss:1.3474\n",
      "Epoch [2/136],loss:1.2452\n",
      "Epoch [2/137],loss:1.0454\n",
      "Epoch [2/138],loss:1.3180\n",
      "Epoch [2/139],loss:1.1102\n",
      "Epoch [2/140],loss:1.3686\n",
      "Epoch [2/141],loss:1.2462\n",
      "Epoch [2/142],loss:1.9600\n",
      "Epoch [2/143],loss:1.3127\n",
      "Epoch [2/144],loss:0.9426\n",
      "Epoch [2/145],loss:1.2720\n",
      "Epoch [2/146],loss:1.4928\n",
      "Epoch [2/147],loss:1.0470\n",
      "Epoch [2/148],loss:1.3824\n",
      "Epoch [2/149],loss:1.6831\n",
      "Epoch [2/150],loss:1.0975\n",
      "Epoch [2/151],loss:0.8806\n",
      "Epoch [2/152],loss:1.1912\n",
      "Epoch [2/153],loss:1.5558\n",
      "Epoch [2/154],loss:0.9974\n",
      "Epoch [2/155],loss:1.6937\n",
      "Epoch [2/156],loss:1.3082\n",
      "Epoch [2/157],loss:1.4257\n",
      "Epoch [2/158],loss:1.3993\n",
      "Epoch [2/159],loss:1.4427\n",
      "Epoch [2/160],loss:0.9678\n",
      "Epoch [2/161],loss:1.3824\n",
      "Epoch [2/162],loss:1.3807\n",
      "Epoch [2/163],loss:1.4376\n",
      "Epoch [2/164],loss:1.4100\n",
      "Epoch [2/165],loss:1.5260\n",
      "Epoch [2/166],loss:0.8340\n",
      "Epoch [2/167],loss:2.1392\n",
      "Epoch [2/168],loss:1.4198\n",
      "Epoch [2/169],loss:1.3751\n",
      "Epoch [2/170],loss:1.3344\n",
      "Epoch [2/171],loss:1.3972\n",
      "Epoch [2/172],loss:0.9095\n",
      "Epoch [2/173],loss:1.2508\n",
      "Epoch [2/174],loss:1.4882\n",
      "Epoch [2/175],loss:1.4340\n",
      "Epoch [2/176],loss:1.0313\n",
      "Epoch [2/177],loss:1.3422\n",
      "Epoch [2/178],loss:1.4276\n",
      "Epoch [2/179],loss:1.2801\n",
      "Epoch [2/180],loss:1.5548\n",
      "Epoch [2/181],loss:2.0353\n",
      "Epoch [2/182],loss:1.4401\n",
      "Epoch [2/183],loss:1.6934\n",
      "Epoch [2/184],loss:0.9579\n",
      "Epoch [2/185],loss:1.3605\n",
      "Epoch [2/186],loss:1.3510\n",
      "Epoch [2/187],loss:1.5085\n",
      "Epoch [2/188],loss:1.4716\n",
      "Epoch [2/189],loss:1.1166\n",
      "Epoch [2/190],loss:1.3925\n",
      "Epoch [2/191],loss:1.6423\n",
      "Epoch [2/192],loss:1.5559\n",
      "Epoch [2/193],loss:1.3948\n",
      "Epoch [2/194],loss:1.1167\n",
      "Epoch [2/195],loss:1.3788\n",
      "Epoch [2/196],loss:1.3600\n",
      "Epoch [2/197],loss:1.0227\n",
      "Epoch [2/198],loss:1.3152\n",
      "Epoch [2/199],loss:1.3392\n",
      "Epoch [2/200],loss:1.4098\n",
      "Epoch [3/1],loss:1.3210\n",
      "Epoch [3/2],loss:1.2718\n",
      "Epoch [3/3],loss:1.3042\n",
      "Epoch [3/4],loss:1.3038\n",
      "Epoch [3/5],loss:1.0877\n",
      "Epoch [3/6],loss:1.0159\n",
      "Epoch [3/7],loss:1.7001\n",
      "Epoch [3/8],loss:1.4779\n",
      "Epoch [3/9],loss:1.3201\n",
      "Epoch [3/10],loss:0.9589\n",
      "Epoch [3/11],loss:1.0754\n",
      "Epoch [3/12],loss:1.5077\n",
      "Epoch [3/13],loss:1.2248\n",
      "Epoch [3/14],loss:1.0807\n",
      "Epoch [3/15],loss:1.1215\n",
      "Epoch [3/16],loss:1.2745\n",
      "Epoch [3/17],loss:1.6036\n",
      "Epoch [3/18],loss:1.2578\n",
      "Epoch [3/19],loss:1.3387\n",
      "Epoch [3/20],loss:1.4007\n",
      "Epoch [3/21],loss:1.1241\n",
      "Epoch [3/22],loss:1.7452\n",
      "Epoch [3/23],loss:1.2851\n",
      "Epoch [3/24],loss:1.2601\n",
      "Epoch [3/25],loss:1.4314\n",
      "Epoch [3/26],loss:1.6372\n",
      "Epoch [3/27],loss:1.3464\n",
      "Epoch [3/28],loss:0.8684\n",
      "Epoch [3/29],loss:1.2783\n",
      "Epoch [3/30],loss:1.2616\n",
      "Epoch [3/31],loss:0.8011\n",
      "Epoch [3/32],loss:0.8357\n",
      "Epoch [3/33],loss:1.5139\n",
      "Epoch [3/34],loss:1.4199\n",
      "Epoch [3/35],loss:0.7825\n",
      "Epoch [3/36],loss:1.4471\n",
      "Epoch [3/37],loss:1.1653\n",
      "Epoch [3/38],loss:1.5177\n",
      "Epoch [3/39],loss:1.0719\n",
      "Epoch [3/40],loss:1.4366\n",
      "Epoch [3/41],loss:1.0745\n",
      "Epoch [3/42],loss:1.5792\n",
      "Epoch [3/43],loss:0.8302\n",
      "Epoch [3/44],loss:1.0503\n",
      "Epoch [3/45],loss:0.8704\n",
      "Epoch [3/46],loss:1.3325\n",
      "Epoch [3/47],loss:1.1209\n",
      "Epoch [3/48],loss:1.4237\n",
      "Epoch [3/49],loss:0.9302\n",
      "Epoch [3/50],loss:1.4309\n",
      "Epoch [3/51],loss:1.4696\n",
      "Epoch [3/52],loss:1.6632\n",
      "Epoch [3/53],loss:1.4612\n",
      "Epoch [3/54],loss:1.2661\n",
      "Epoch [3/55],loss:1.4121\n",
      "Epoch [3/56],loss:1.3860\n",
      "Epoch [3/57],loss:1.0985\n",
      "Epoch [3/58],loss:0.9384\n",
      "Epoch [3/59],loss:1.6391\n",
      "Epoch [3/60],loss:0.6578\n",
      "Epoch [3/61],loss:1.3679\n",
      "Epoch [3/62],loss:1.3830\n",
      "Epoch [3/63],loss:1.4552\n",
      "Epoch [3/64],loss:1.3523\n",
      "Epoch [3/65],loss:1.4862\n",
      "Epoch [3/66],loss:1.4752\n",
      "Epoch [3/67],loss:1.3399\n",
      "Epoch [3/68],loss:1.3996\n",
      "Epoch [3/69],loss:1.1417\n",
      "Epoch [3/70],loss:2.4787\n",
      "Epoch [3/71],loss:1.1993\n",
      "Epoch [3/72],loss:0.7462\n",
      "Epoch [3/73],loss:0.9140\n",
      "Epoch [3/74],loss:1.4178\n",
      "Epoch [3/75],loss:0.9852\n",
      "Epoch [3/76],loss:1.4195\n",
      "Epoch [3/77],loss:1.1066\n",
      "Epoch [3/78],loss:1.3229\n",
      "Epoch [3/79],loss:1.3900\n",
      "Epoch [3/80],loss:1.4151\n",
      "Epoch [3/81],loss:0.8824\n",
      "Epoch [3/82],loss:1.3577\n",
      "Epoch [3/83],loss:0.8965\n",
      "Epoch [3/84],loss:1.2717\n",
      "Epoch [3/85],loss:1.6659\n",
      "Epoch [3/86],loss:1.4310\n",
      "Epoch [3/87],loss:0.6872\n",
      "Epoch [3/88],loss:0.6948\n",
      "Epoch [3/89],loss:0.8068\n",
      "Epoch [3/90],loss:0.8313\n",
      "Epoch [3/91],loss:1.3994\n",
      "Epoch [3/92],loss:1.2102\n",
      "Epoch [3/93],loss:1.7686\n",
      "Epoch [3/94],loss:1.3145\n",
      "Epoch [3/95],loss:1.3341\n",
      "Epoch [3/96],loss:0.6969\n",
      "Epoch [3/97],loss:1.3592\n",
      "Epoch [3/98],loss:1.6252\n",
      "Epoch [3/99],loss:0.4814\n",
      "Epoch [3/100],loss:1.6653\n",
      "Epoch [3/101],loss:0.6303\n",
      "Epoch [3/102],loss:1.3723\n",
      "Epoch [3/103],loss:1.4393\n",
      "Epoch [3/104],loss:1.9811\n",
      "Epoch [3/105],loss:1.2962\n",
      "Epoch [3/106],loss:1.5123\n",
      "Epoch [3/107],loss:1.8886\n",
      "Epoch [3/108],loss:0.8570\n",
      "Epoch [3/109],loss:1.7304\n",
      "Epoch [3/110],loss:0.5437\n",
      "Epoch [3/111],loss:1.3229\n",
      "Epoch [3/112],loss:0.8481\n",
      "Epoch [3/113],loss:1.3393\n",
      "Epoch [3/114],loss:1.3581\n",
      "Epoch [3/115],loss:0.9483\n",
      "Epoch [3/116],loss:2.4667\n",
      "Epoch [3/117],loss:1.6884\n",
      "Epoch [3/118],loss:1.3397\n",
      "Epoch [3/119],loss:0.6503\n",
      "Epoch [3/120],loss:0.6462\n",
      "Epoch [3/121],loss:1.3104\n",
      "Epoch [3/122],loss:1.2171\n",
      "Epoch [3/123],loss:0.9087\n",
      "Epoch [3/124],loss:1.6516\n",
      "Epoch [3/125],loss:1.4564\n",
      "Epoch [3/126],loss:1.3438\n",
      "Epoch [3/127],loss:1.3660\n",
      "Epoch [3/128],loss:1.2098\n",
      "Epoch [3/129],loss:1.4396\n",
      "Epoch [3/130],loss:1.2918\n",
      "Epoch [3/131],loss:1.4576\n",
      "Epoch [3/132],loss:1.5921\n",
      "Epoch [3/133],loss:1.1568\n",
      "Epoch [3/134],loss:1.3778\n",
      "Epoch [3/135],loss:1.1805\n",
      "Epoch [3/136],loss:1.1282\n",
      "Epoch [3/137],loss:0.8457\n",
      "Epoch [3/138],loss:1.1086\n",
      "Epoch [3/139],loss:0.9952\n",
      "Epoch [3/140],loss:1.1390\n",
      "Epoch [3/141],loss:1.1515\n",
      "Epoch [3/142],loss:2.5462\n",
      "Epoch [3/143],loss:1.2987\n",
      "Epoch [3/144],loss:0.8986\n",
      "Epoch [3/145],loss:1.4695\n",
      "Epoch [3/146],loss:1.6305\n",
      "Epoch [3/147],loss:0.9529\n",
      "Epoch [3/148],loss:1.3417\n",
      "Epoch [3/149],loss:1.6166\n",
      "Epoch [3/150],loss:1.0451\n",
      "Epoch [3/151],loss:0.6143\n",
      "Epoch [3/152],loss:1.1199\n",
      "Epoch [3/153],loss:1.7109\n",
      "Epoch [3/154],loss:0.9057\n",
      "Epoch [3/155],loss:1.6547\n",
      "Epoch [3/156],loss:1.1016\n",
      "Epoch [3/157],loss:1.3295\n",
      "Epoch [3/158],loss:1.6111\n",
      "Epoch [3/159],loss:1.3769\n",
      "Epoch [3/160],loss:0.9040\n",
      "Epoch [3/161],loss:1.2205\n",
      "Epoch [3/162],loss:1.3257\n",
      "Epoch [3/163],loss:1.4601\n",
      "Epoch [3/164],loss:1.3226\n",
      "Epoch [3/165],loss:1.4787\n",
      "Epoch [3/166],loss:0.6101\n",
      "Epoch [3/167],loss:2.6101\n",
      "Epoch [3/168],loss:1.4111\n",
      "Epoch [3/169],loss:1.2901\n",
      "Epoch [3/170],loss:1.1883\n",
      "Epoch [3/171],loss:1.3516\n",
      "Epoch [3/172],loss:0.7583\n",
      "Epoch [3/173],loss:1.0763\n",
      "Epoch [3/174],loss:1.5458\n",
      "Epoch [3/175],loss:1.3875\n",
      "Epoch [3/176],loss:0.9929\n",
      "Epoch [3/177],loss:1.2615\n",
      "Epoch [3/178],loss:1.4114\n",
      "Epoch [3/179],loss:1.1067\n",
      "Epoch [3/180],loss:1.4838\n",
      "Epoch [3/181],loss:2.4231\n",
      "Epoch [3/182],loss:1.3658\n",
      "Epoch [3/183],loss:1.8464\n",
      "Epoch [3/184],loss:0.7203\n",
      "Epoch [3/185],loss:1.4063\n",
      "Epoch [3/186],loss:1.2898\n",
      "Epoch [3/187],loss:1.4968\n",
      "Epoch [3/188],loss:1.5668\n",
      "Epoch [3/189],loss:0.8710\n",
      "Epoch [3/190],loss:1.3614\n",
      "Epoch [3/191],loss:1.7275\n",
      "Epoch [3/192],loss:1.5056\n",
      "Epoch [3/193],loss:1.3040\n",
      "Epoch [3/194],loss:1.1328\n",
      "Epoch [3/195],loss:1.3517\n",
      "Epoch [3/196],loss:1.3267\n",
      "Epoch [3/197],loss:0.9188\n",
      "Epoch [3/198],loss:1.2509\n",
      "Epoch [3/199],loss:1.3468\n",
      "Epoch [3/200],loss:1.4213\n",
      "Epoch [4/1],loss:1.1721\n",
      "Epoch [4/2],loss:1.2040\n",
      "Epoch [4/3],loss:1.1166\n",
      "Epoch [4/4],loss:1.2607\n",
      "Epoch [4/5],loss:0.9610\n",
      "Epoch [4/6],loss:0.9468\n",
      "Epoch [4/7],loss:1.7367\n",
      "Epoch [4/8],loss:1.4068\n",
      "Epoch [4/9],loss:1.1766\n",
      "Epoch [4/10],loss:0.8345\n",
      "Epoch [4/11],loss:1.0829\n",
      "Epoch [4/12],loss:1.4614\n",
      "Epoch [4/13],loss:1.1617\n",
      "Epoch [4/14],loss:1.0365\n",
      "Epoch [4/15],loss:1.1798\n",
      "Epoch [4/16],loss:1.2193\n",
      "Epoch [4/17],loss:1.5227\n",
      "Epoch [4/18],loss:1.2163\n",
      "Epoch [4/19],loss:1.3044\n",
      "Epoch [4/20],loss:1.3896\n",
      "Epoch [4/21],loss:1.1693\n",
      "Epoch [4/22],loss:1.7153\n",
      "Epoch [4/23],loss:0.9983\n",
      "Epoch [4/24],loss:1.2142\n",
      "Epoch [4/25],loss:1.5048\n",
      "Epoch [4/26],loss:1.7641\n",
      "Epoch [4/27],loss:1.2661\n",
      "Epoch [4/28],loss:0.7375\n",
      "Epoch [4/29],loss:1.3122\n",
      "Epoch [4/30],loss:1.0559\n",
      "Epoch [4/31],loss:0.6022\n",
      "Epoch [4/32],loss:0.6139\n",
      "Epoch [4/33],loss:1.5385\n",
      "Epoch [4/34],loss:1.4818\n",
      "Epoch [4/35],loss:0.5353\n",
      "Epoch [4/36],loss:1.3527\n",
      "Epoch [4/37],loss:1.1054\n",
      "Epoch [4/38],loss:1.4302\n",
      "Epoch [4/39],loss:1.0040\n",
      "Epoch [4/40],loss:1.2132\n",
      "Epoch [4/41],loss:1.0111\n",
      "Epoch [4/42],loss:1.3496\n",
      "Epoch [4/43],loss:0.5741\n",
      "Epoch [4/44],loss:0.7191\n",
      "Epoch [4/45],loss:0.7664\n",
      "Epoch [4/46],loss:1.3570\n",
      "Epoch [4/47],loss:1.0445\n",
      "Epoch [4/48],loss:1.2027\n",
      "Epoch [4/49],loss:0.8724\n",
      "Epoch [4/50],loss:1.4134\n",
      "Epoch [4/51],loss:1.3530\n",
      "Epoch [4/52],loss:1.7663\n",
      "Epoch [4/53],loss:1.2586\n",
      "Epoch [4/54],loss:1.1324\n",
      "Epoch [4/55],loss:1.2855\n",
      "Epoch [4/56],loss:1.2630\n",
      "Epoch [4/57],loss:0.9713\n",
      "Epoch [4/58],loss:0.8718\n",
      "Epoch [4/59],loss:1.6948\n",
      "Epoch [4/60],loss:0.4068\n",
      "Epoch [4/61],loss:1.2197\n",
      "Epoch [4/62],loss:1.3944\n",
      "Epoch [4/63],loss:1.2969\n",
      "Epoch [4/64],loss:1.2245\n",
      "Epoch [4/65],loss:1.3441\n",
      "Epoch [4/66],loss:1.5100\n",
      "Epoch [4/67],loss:1.3311\n",
      "Epoch [4/68],loss:1.3059\n",
      "Epoch [4/69],loss:1.1170\n",
      "Epoch [4/70],loss:2.8988\n",
      "Epoch [4/71],loss:1.4666\n",
      "Epoch [4/72],loss:0.7725\n",
      "Epoch [4/73],loss:0.8941\n",
      "Epoch [4/74],loss:1.1321\n",
      "Epoch [4/75],loss:0.6853\n",
      "Epoch [4/76],loss:1.6214\n",
      "Epoch [4/77],loss:1.0036\n",
      "Epoch [4/78],loss:1.1431\n",
      "Epoch [4/79],loss:1.4587\n",
      "Epoch [4/80],loss:1.1603\n",
      "Epoch [4/81],loss:0.7051\n",
      "Epoch [4/82],loss:1.3468\n",
      "Epoch [4/83],loss:0.8369\n",
      "Epoch [4/84],loss:1.0415\n",
      "Epoch [4/85],loss:1.6480\n",
      "Epoch [4/86],loss:1.5503\n",
      "Epoch [4/87],loss:0.5272\n",
      "Epoch [4/88],loss:0.6520\n",
      "Epoch [4/89],loss:0.6180\n",
      "Epoch [4/90],loss:0.7890\n",
      "Epoch [4/91],loss:1.3907\n",
      "Epoch [4/92],loss:1.1108\n",
      "Epoch [4/93],loss:1.2199\n",
      "Epoch [4/94],loss:1.2726\n",
      "Epoch [4/95],loss:1.2243\n",
      "Epoch [4/96],loss:0.6802\n",
      "Epoch [4/97],loss:1.2987\n",
      "Epoch [4/98],loss:1.5742\n",
      "Epoch [4/99],loss:0.2850\n",
      "Epoch [4/100],loss:1.7262\n",
      "Epoch [4/101],loss:0.3428\n",
      "Epoch [4/102],loss:1.3315\n",
      "Epoch [4/103],loss:1.4484\n",
      "Epoch [4/104],loss:2.0810\n",
      "Epoch [4/105],loss:0.9856\n",
      "Epoch [4/106],loss:1.4867\n",
      "Epoch [4/107],loss:1.8129\n",
      "Epoch [4/108],loss:0.8111\n",
      "Epoch [4/109],loss:1.6306\n",
      "Epoch [4/110],loss:0.3527\n",
      "Epoch [4/111],loss:1.3163\n",
      "Epoch [4/112],loss:0.8745\n",
      "Epoch [4/113],loss:1.2111\n",
      "Epoch [4/114],loss:1.4508\n",
      "Epoch [4/115],loss:0.9767\n",
      "Epoch [4/116],loss:2.8385\n",
      "Epoch [4/117],loss:1.5463\n",
      "Epoch [4/118],loss:1.1516\n",
      "Epoch [4/119],loss:0.4124\n",
      "Epoch [4/120],loss:0.4149\n",
      "Epoch [4/121],loss:1.2756\n",
      "Epoch [4/122],loss:1.1247\n",
      "Epoch [4/123],loss:0.8619\n",
      "Epoch [4/124],loss:1.5152\n",
      "Epoch [4/125],loss:1.3248\n",
      "Epoch [4/126],loss:1.4423\n",
      "Epoch [4/127],loss:1.3561\n",
      "Epoch [4/128],loss:0.8891\n",
      "Epoch [4/129],loss:1.4386\n",
      "Epoch [4/130],loss:1.3083\n",
      "Epoch [4/131],loss:1.2661\n",
      "Epoch [4/132],loss:1.5091\n",
      "Epoch [4/133],loss:0.8960\n",
      "Epoch [4/134],loss:1.2655\n",
      "Epoch [4/135],loss:0.8944\n",
      "Epoch [4/136],loss:1.0753\n",
      "Epoch [4/137],loss:0.7495\n",
      "Epoch [4/138],loss:0.7605\n",
      "Epoch [4/139],loss:0.9050\n",
      "Epoch [4/140],loss:0.5964\n",
      "Epoch [4/141],loss:1.1165\n",
      "Epoch [4/142],loss:3.0686\n",
      "Epoch [4/143],loss:1.3382\n",
      "Epoch [4/144],loss:0.9938\n",
      "Epoch [4/145],loss:2.0520\n",
      "Epoch [4/146],loss:1.7646\n",
      "Epoch [4/147],loss:0.8830\n",
      "Epoch [4/148],loss:1.2895\n",
      "Epoch [4/149],loss:1.0912\n",
      "Epoch [4/150],loss:1.0478\n",
      "Epoch [4/151],loss:0.4558\n",
      "Epoch [4/152],loss:1.0477\n",
      "Epoch [4/153],loss:1.7341\n",
      "Epoch [4/154],loss:0.8833\n",
      "Epoch [4/155],loss:1.2918\n",
      "Epoch [4/156],loss:0.8134\n",
      "Epoch [4/157],loss:1.1356\n",
      "Epoch [4/158],loss:1.8877\n",
      "Epoch [4/159],loss:1.2310\n",
      "Epoch [4/160],loss:0.8259\n",
      "Epoch [4/161],loss:1.0621\n",
      "Epoch [4/162],loss:1.3304\n",
      "Epoch [4/163],loss:1.5434\n",
      "Epoch [4/164],loss:1.2643\n",
      "Epoch [4/165],loss:1.0788\n",
      "Epoch [4/166],loss:0.4846\n",
      "Epoch [4/167],loss:2.9073\n",
      "Epoch [4/168],loss:1.4284\n",
      "Epoch [4/169],loss:1.2346\n",
      "Epoch [4/170],loss:1.0142\n",
      "Epoch [4/171],loss:1.2904\n",
      "Epoch [4/172],loss:0.6928\n",
      "Epoch [4/173],loss:0.9138\n",
      "Epoch [4/174],loss:1.5492\n",
      "Epoch [4/175],loss:1.2051\n",
      "Epoch [4/176],loss:0.9273\n",
      "Epoch [4/177],loss:1.1869\n",
      "Epoch [4/178],loss:1.3799\n",
      "Epoch [4/179],loss:0.9021\n",
      "Epoch [4/180],loss:1.2032\n",
      "Epoch [4/181],loss:2.6138\n",
      "Epoch [4/182],loss:1.2404\n",
      "Epoch [4/183],loss:1.8289\n",
      "Epoch [4/184],loss:0.4124\n",
      "Epoch [4/185],loss:1.5592\n",
      "Epoch [4/186],loss:1.2146\n",
      "Epoch [4/187],loss:1.4217\n",
      "Epoch [4/188],loss:1.7041\n",
      "Epoch [4/189],loss:0.5899\n",
      "Epoch [4/190],loss:1.3160\n",
      "Epoch [4/191],loss:1.5588\n",
      "Epoch [4/192],loss:1.1004\n",
      "Epoch [4/193],loss:1.1263\n",
      "Epoch [4/194],loss:1.2133\n",
      "Epoch [4/195],loss:1.3248\n",
      "Epoch [4/196],loss:1.2699\n",
      "Epoch [4/197],loss:0.8829\n",
      "Epoch [4/198],loss:1.1728\n",
      "Epoch [4/199],loss:1.3958\n",
      "Epoch [4/200],loss:1.3962\n",
      "Epoch [5/1],loss:0.8824\n",
      "Epoch [5/2],loss:0.9224\n",
      "Epoch [5/3],loss:0.6117\n",
      "Epoch [5/4],loss:1.2030\n",
      "Epoch [5/5],loss:0.7930\n",
      "Epoch [5/6],loss:1.0030\n",
      "Epoch [5/7],loss:1.4420\n",
      "Epoch [5/8],loss:1.0545\n",
      "Epoch [5/9],loss:0.9330\n",
      "Epoch [5/10],loss:0.7267\n",
      "Epoch [5/11],loss:1.1271\n",
      "Epoch [5/12],loss:1.4556\n",
      "Epoch [5/13],loss:1.0420\n",
      "Epoch [5/14],loss:0.8678\n",
      "Epoch [5/15],loss:1.3480\n",
      "Epoch [5/16],loss:1.1462\n",
      "Epoch [5/17],loss:1.4554\n",
      "Epoch [5/18],loss:1.2178\n",
      "Epoch [5/19],loss:1.2713\n",
      "Epoch [5/20],loss:1.3555\n",
      "Epoch [5/21],loss:1.3128\n",
      "Epoch [5/22],loss:1.5572\n",
      "Epoch [5/23],loss:0.6009\n",
      "Epoch [5/24],loss:1.1468\n",
      "Epoch [5/25],loss:1.7415\n",
      "Epoch [5/26],loss:1.7966\n",
      "Epoch [5/27],loss:1.1985\n",
      "Epoch [5/28],loss:0.5671\n",
      "Epoch [5/29],loss:1.3582\n",
      "Epoch [5/30],loss:0.7844\n",
      "Epoch [5/31],loss:0.3562\n",
      "Epoch [5/32],loss:0.3080\n",
      "Epoch [5/33],loss:1.4760\n",
      "Epoch [5/34],loss:1.7253\n",
      "Epoch [5/35],loss:0.2493\n",
      "Epoch [5/36],loss:1.1695\n",
      "Epoch [5/37],loss:1.0086\n",
      "Epoch [5/38],loss:1.0649\n",
      "Epoch [5/39],loss:0.9372\n",
      "Epoch [5/40],loss:0.8465\n",
      "Epoch [5/41],loss:0.8975\n",
      "Epoch [5/42],loss:0.8002\n",
      "Epoch [5/43],loss:0.2689\n",
      "Epoch [5/44],loss:0.2816\n",
      "Epoch [5/45],loss:0.7128\n",
      "Epoch [5/46],loss:1.4043\n",
      "Epoch [5/47],loss:0.9149\n",
      "Epoch [5/48],loss:0.8046\n",
      "Epoch [5/49],loss:0.7544\n",
      "Epoch [5/50],loss:1.3542\n",
      "Epoch [5/51],loss:1.0643\n",
      "Epoch [5/52],loss:1.6396\n",
      "Epoch [5/53],loss:1.0107\n",
      "Epoch [5/54],loss:0.8944\n",
      "Epoch [5/55],loss:1.1068\n",
      "Epoch [5/56],loss:1.0033\n",
      "Epoch [5/57],loss:0.8392\n",
      "Epoch [5/58],loss:0.8650\n",
      "Epoch [5/59],loss:1.2145\n",
      "Epoch [5/60],loss:0.1927\n",
      "Epoch [5/61],loss:0.9113\n",
      "Epoch [5/62],loss:1.4169\n",
      "Epoch [5/63],loss:0.8694\n",
      "Epoch [5/64],loss:1.1330\n",
      "Epoch [5/65],loss:1.2613\n",
      "Epoch [5/66],loss:1.4745\n",
      "Epoch [5/67],loss:1.2670\n",
      "Epoch [5/68],loss:1.0857\n",
      "Epoch [5/69],loss:1.1987\n",
      "Epoch [5/70],loss:3.3259\n",
      "Epoch [5/71],loss:1.8234\n",
      "Epoch [5/72],loss:0.8918\n",
      "Epoch [5/73],loss:0.9535\n",
      "Epoch [5/74],loss:0.6643\n",
      "Epoch [5/75],loss:0.2514\n",
      "Epoch [5/76],loss:1.9847\n",
      "Epoch [5/77],loss:1.0505\n",
      "Epoch [5/78],loss:0.9107\n",
      "Epoch [5/79],loss:1.6029\n",
      "Epoch [5/80],loss:0.7726\n",
      "Epoch [5/81],loss:0.4592\n",
      "Epoch [5/82],loss:1.3542\n",
      "Epoch [5/83],loss:0.8645\n",
      "Epoch [5/84],loss:0.7736\n",
      "Epoch [5/85],loss:1.3200\n",
      "Epoch [5/86],loss:1.6792\n",
      "Epoch [5/87],loss:0.3656\n",
      "Epoch [5/88],loss:0.5754\n",
      "Epoch [5/89],loss:0.4131\n",
      "Epoch [5/90],loss:0.6612\n",
      "Epoch [5/91],loss:1.4134\n",
      "Epoch [5/92],loss:0.8947\n",
      "Epoch [5/93],loss:0.5544\n",
      "Epoch [5/94],loss:1.2092\n",
      "Epoch [5/95],loss:0.9665\n",
      "Epoch [5/96],loss:0.6466\n",
      "Epoch [5/97],loss:1.1224\n",
      "Epoch [5/98],loss:0.9806\n",
      "Epoch [5/99],loss:0.1698\n",
      "Epoch [5/100],loss:1.6767\n",
      "Epoch [5/101],loss:0.1672\n",
      "Epoch [5/102],loss:1.2370\n",
      "Epoch [5/103],loss:1.4263\n",
      "Epoch [5/104],loss:1.8430\n",
      "Epoch [5/105],loss:0.6106\n",
      "Epoch [5/106],loss:1.1393\n",
      "Epoch [5/107],loss:1.4751\n",
      "Epoch [5/108],loss:0.8266\n",
      "Epoch [5/109],loss:1.4466\n",
      "Epoch [5/110],loss:0.2153\n",
      "Epoch [5/111],loss:1.2245\n",
      "Epoch [5/112],loss:0.9629\n",
      "Epoch [5/113],loss:0.9609\n",
      "Epoch [5/114],loss:1.5839\n",
      "Epoch [5/115],loss:0.9723\n",
      "Epoch [5/116],loss:3.1721\n",
      "Epoch [5/117],loss:1.3942\n",
      "Epoch [5/118],loss:0.7649\n",
      "Epoch [5/119],loss:0.1938\n",
      "Epoch [5/120],loss:0.1875\n",
      "Epoch [5/121],loss:1.1748\n",
      "Epoch [5/122],loss:0.9669\n",
      "Epoch [5/123],loss:0.7577\n",
      "Epoch [5/124],loss:1.3400\n",
      "Epoch [5/125],loss:1.0741\n",
      "Epoch [5/126],loss:1.4354\n",
      "Epoch [5/127],loss:1.3737\n",
      "Epoch [5/128],loss:0.5142\n",
      "Epoch [5/129],loss:1.4647\n",
      "Epoch [5/130],loss:1.2630\n",
      "Epoch [5/131],loss:0.9440\n",
      "Epoch [5/132],loss:1.3309\n",
      "Epoch [5/133],loss:0.5948\n",
      "Epoch [5/134],loss:0.9268\n",
      "Epoch [5/135],loss:0.5491\n",
      "Epoch [5/136],loss:1.0539\n",
      "Epoch [5/137],loss:0.4267\n",
      "Epoch [5/138],loss:0.3876\n",
      "Epoch [5/139],loss:0.7213\n",
      "Epoch [5/140],loss:0.1786\n",
      "Epoch [5/141],loss:1.0875\n",
      "Epoch [5/142],loss:3.4096\n",
      "Epoch [5/143],loss:1.3152\n",
      "Epoch [5/144],loss:1.1621\n",
      "Epoch [5/145],loss:2.5160\n",
      "Epoch [5/146],loss:2.2649\n",
      "Epoch [5/147],loss:0.7337\n",
      "Epoch [5/148],loss:1.2391\n",
      "Epoch [5/149],loss:0.4962\n",
      "Epoch [5/150],loss:1.0801\n",
      "Epoch [5/151],loss:0.2769\n",
      "Epoch [5/152],loss:0.8816\n",
      "Epoch [5/153],loss:1.6249\n",
      "Epoch [5/154],loss:0.8866\n",
      "Epoch [5/155],loss:0.9334\n",
      "Epoch [5/156],loss:0.5369\n",
      "Epoch [5/157],loss:0.8226\n",
      "Epoch [5/158],loss:1.6379\n",
      "Epoch [5/159],loss:1.1040\n",
      "Epoch [5/160],loss:0.6538\n",
      "Epoch [5/161],loss:1.0374\n",
      "Epoch [5/162],loss:1.4328\n",
      "Epoch [5/163],loss:1.5573\n",
      "Epoch [5/164],loss:1.2602\n",
      "Epoch [5/165],loss:0.6139\n",
      "Epoch [5/166],loss:0.3484\n",
      "Epoch [5/167],loss:3.0316\n",
      "Epoch [5/168],loss:1.2954\n",
      "Epoch [5/169],loss:1.1717\n",
      "Epoch [5/170],loss:0.8407\n",
      "Epoch [5/171],loss:1.1608\n",
      "Epoch [5/172],loss:0.5180\n",
      "Epoch [5/173],loss:0.9249\n",
      "Epoch [5/174],loss:1.3556\n",
      "Epoch [5/175],loss:0.9335\n",
      "Epoch [5/176],loss:0.7667\n",
      "Epoch [5/177],loss:1.0990\n",
      "Epoch [5/178],loss:1.3336\n",
      "Epoch [5/179],loss:0.6297\n",
      "Epoch [5/180],loss:0.8347\n",
      "Epoch [5/181],loss:2.6453\n",
      "Epoch [5/182],loss:1.0583\n",
      "Epoch [5/183],loss:1.2011\n",
      "Epoch [5/184],loss:0.2388\n",
      "Epoch [5/185],loss:1.5761\n",
      "Epoch [5/186],loss:1.0717\n",
      "Epoch [5/187],loss:1.2674\n",
      "Epoch [5/188],loss:1.8641\n",
      "Epoch [5/189],loss:0.3372\n",
      "Epoch [5/190],loss:1.2549\n",
      "Epoch [5/191],loss:0.9225\n",
      "Epoch [5/192],loss:0.4586\n",
      "Epoch [5/193],loss:0.8700\n",
      "Epoch [5/194],loss:1.3281\n",
      "Epoch [5/195],loss:1.2685\n",
      "Epoch [5/196],loss:1.1261\n",
      "Epoch [5/197],loss:0.7175\n",
      "Epoch [5/198],loss:1.0495\n",
      "Epoch [5/199],loss:1.2909\n",
      "Epoch [5/200],loss:1.2997\n",
      "Epoch [6/1],loss:0.4388\n",
      "Epoch [6/2],loss:0.5254\n",
      "Epoch [6/3],loss:0.2674\n",
      "Epoch [6/4],loss:1.0217\n",
      "Epoch [6/5],loss:0.6306\n",
      "Epoch [6/6],loss:1.0159\n",
      "Epoch [6/7],loss:1.1638\n",
      "Epoch [6/8],loss:0.5911\n",
      "Epoch [6/9],loss:0.6420\n",
      "Epoch [6/10],loss:0.5108\n",
      "Epoch [6/11],loss:0.9819\n",
      "Epoch [6/12],loss:1.5106\n",
      "Epoch [6/13],loss:0.8510\n",
      "Epoch [6/14],loss:0.5981\n",
      "Epoch [6/15],loss:1.6324\n",
      "Epoch [6/16],loss:0.9863\n",
      "Epoch [6/17],loss:1.3557\n",
      "Epoch [6/18],loss:0.9915\n",
      "Epoch [6/19],loss:1.0961\n",
      "Epoch [6/20],loss:1.1989\n",
      "Epoch [6/21],loss:1.4609\n",
      "Epoch [6/22],loss:1.2913\n",
      "Epoch [6/23],loss:0.2486\n",
      "Epoch [6/24],loss:0.9633\n",
      "Epoch [6/25],loss:1.7910\n",
      "Epoch [6/26],loss:1.0788\n",
      "Epoch [6/27],loss:1.1259\n",
      "Epoch [6/28],loss:0.4469\n",
      "Epoch [6/29],loss:0.9757\n",
      "Epoch [6/30],loss:0.5781\n",
      "Epoch [6/31],loss:0.2299\n",
      "Epoch [6/32],loss:0.1641\n",
      "Epoch [6/33],loss:1.2825\n",
      "Epoch [6/34],loss:1.8548\n",
      "Epoch [6/35],loss:0.1408\n",
      "Epoch [6/36],loss:0.9011\n",
      "Epoch [6/37],loss:0.8217\n",
      "Epoch [6/38],loss:0.5831\n",
      "Epoch [6/39],loss:0.9673\n",
      "Epoch [6/40],loss:0.5299\n",
      "Epoch [6/41],loss:0.6954\n",
      "Epoch [6/42],loss:0.4746\n",
      "Epoch [6/43],loss:0.1482\n",
      "Epoch [6/44],loss:0.1443\n",
      "Epoch [6/45],loss:0.6664\n",
      "Epoch [6/46],loss:1.2014\n",
      "Epoch [6/47],loss:0.7078\n",
      "Epoch [6/48],loss:0.3885\n",
      "Epoch [6/49],loss:0.6027\n",
      "Epoch [6/50],loss:1.1755\n",
      "Epoch [6/51],loss:0.8046\n",
      "Epoch [6/52],loss:1.2410\n",
      "Epoch [6/53],loss:0.7507\n",
      "Epoch [6/54],loss:0.6085\n",
      "Epoch [6/55],loss:0.9970\n",
      "Epoch [6/56],loss:0.6266\n",
      "Epoch [6/57],loss:0.7026\n",
      "Epoch [6/58],loss:1.0485\n",
      "Epoch [6/59],loss:0.5278\n",
      "Epoch [6/60],loss:0.1181\n",
      "Epoch [6/61],loss:0.4869\n",
      "Epoch [6/62],loss:1.2048\n",
      "Epoch [6/63],loss:0.4949\n",
      "Epoch [6/64],loss:1.0604\n",
      "Epoch [6/65],loss:1.2442\n",
      "Epoch [6/66],loss:1.4440\n",
      "Epoch [6/67],loss:1.0553\n",
      "Epoch [6/68],loss:0.8305\n",
      "Epoch [6/69],loss:1.5104\n",
      "Epoch [6/70],loss:3.5614\n",
      "Epoch [6/71],loss:1.2367\n",
      "Epoch [6/72],loss:0.8712\n",
      "Epoch [6/73],loss:1.0000\n",
      "Epoch [6/74],loss:0.2973\n",
      "Epoch [6/75],loss:0.1212\n",
      "Epoch [6/76],loss:1.7199\n",
      "Epoch [6/77],loss:1.1525\n",
      "Epoch [6/78],loss:0.9318\n",
      "Epoch [6/79],loss:1.4855\n",
      "Epoch [6/80],loss:0.5984\n",
      "Epoch [6/81],loss:0.2744\n",
      "Epoch [6/82],loss:1.4600\n",
      "Epoch [6/83],loss:0.6774\n",
      "Epoch [6/84],loss:0.7981\n",
      "Epoch [6/85],loss:0.8735\n",
      "Epoch [6/86],loss:1.3661\n",
      "Epoch [6/87],loss:0.2383\n",
      "Epoch [6/88],loss:0.4394\n",
      "Epoch [6/89],loss:0.3170\n",
      "Epoch [6/90],loss:0.5358\n",
      "Epoch [6/91],loss:1.5362\n",
      "Epoch [6/92],loss:0.6415\n",
      "Epoch [6/93],loss:0.3854\n",
      "Epoch [6/94],loss:1.0850\n",
      "Epoch [6/95],loss:0.4965\n",
      "Epoch [6/96],loss:0.5384\n",
      "Epoch [6/97],loss:0.6588\n",
      "Epoch [6/98],loss:0.4351\n",
      "Epoch [6/99],loss:0.1706\n",
      "Epoch [6/100],loss:1.4558\n",
      "Epoch [6/101],loss:0.1524\n",
      "Epoch [6/102],loss:1.0278\n",
      "Epoch [6/103],loss:1.0917\n",
      "Epoch [6/104],loss:1.3806\n",
      "Epoch [6/105],loss:0.3061\n",
      "Epoch [6/106],loss:0.6189\n",
      "Epoch [6/107],loss:1.1158\n",
      "Epoch [6/108],loss:0.9372\n",
      "Epoch [6/109],loss:1.3648\n",
      "Epoch [6/110],loss:0.2152\n",
      "Epoch [6/111],loss:0.9566\n",
      "Epoch [6/112],loss:0.9642\n",
      "Epoch [6/113],loss:0.6661\n",
      "Epoch [6/114],loss:1.1658\n",
      "Epoch [6/115],loss:0.6047\n",
      "Epoch [6/116],loss:3.1501\n",
      "Epoch [6/117],loss:1.0730\n",
      "Epoch [6/118],loss:0.3533\n",
      "Epoch [6/119],loss:0.1668\n",
      "Epoch [6/120],loss:0.1455\n",
      "Epoch [6/121],loss:0.9224\n",
      "Epoch [6/122],loss:0.8406\n",
      "Epoch [6/123],loss:0.5360\n",
      "Epoch [6/124],loss:1.0219\n",
      "Epoch [6/125],loss:0.8688\n",
      "Epoch [6/126],loss:0.9667\n",
      "Epoch [6/127],loss:1.1073\n",
      "Epoch [6/128],loss:0.2604\n",
      "Epoch [6/129],loss:1.6089\n",
      "Epoch [6/130],loss:1.0301\n",
      "Epoch [6/131],loss:0.6985\n",
      "Epoch [6/132],loss:1.1020\n",
      "Epoch [6/133],loss:0.3615\n",
      "Epoch [6/134],loss:0.4123\n",
      "Epoch [6/135],loss:0.3181\n",
      "Epoch [6/136],loss:0.9531\n",
      "Epoch [6/137],loss:0.2915\n",
      "Epoch [6/138],loss:0.1526\n",
      "Epoch [6/139],loss:0.4582\n",
      "Epoch [6/140],loss:0.1498\n",
      "Epoch [6/141],loss:0.8408\n",
      "Epoch [6/142],loss:3.3894\n",
      "Epoch [6/143],loss:1.0371\n",
      "Epoch [6/144],loss:1.1821\n",
      "Epoch [6/145],loss:2.2830\n",
      "Epoch [6/146],loss:2.8060\n",
      "Epoch [6/147],loss:0.5174\n",
      "Epoch [6/148],loss:0.9871\n",
      "Epoch [6/149],loss:0.4125\n",
      "Epoch [6/150],loss:1.2106\n",
      "Epoch [6/151],loss:0.2388\n",
      "Epoch [6/152],loss:0.6417\n",
      "Epoch [6/153],loss:1.4044\n",
      "Epoch [6/154],loss:0.9472\n",
      "Epoch [6/155],loss:0.8384\n",
      "Epoch [6/156],loss:0.3509\n",
      "Epoch [6/157],loss:0.4574\n",
      "Epoch [6/158],loss:1.0032\n",
      "Epoch [6/159],loss:0.7952\n",
      "Epoch [6/160],loss:0.5708\n",
      "Epoch [6/161],loss:1.1432\n",
      "Epoch [6/162],loss:1.6210\n",
      "Epoch [6/163],loss:1.4324\n",
      "Epoch [6/164],loss:1.3450\n",
      "Epoch [6/165],loss:0.2940\n",
      "Epoch [6/166],loss:0.2557\n",
      "Epoch [6/167],loss:3.0297\n",
      "Epoch [6/168],loss:1.0178\n",
      "Epoch [6/169],loss:0.9464\n",
      "Epoch [6/170],loss:0.6418\n",
      "Epoch [6/171],loss:0.9774\n",
      "Epoch [6/172],loss:0.3402\n",
      "Epoch [6/173],loss:1.2385\n",
      "Epoch [6/174],loss:1.0549\n",
      "Epoch [6/175],loss:0.6079\n",
      "Epoch [6/176],loss:0.5231\n",
      "Epoch [6/177],loss:0.8669\n",
      "Epoch [6/178],loss:1.0703\n",
      "Epoch [6/179],loss:0.2923\n",
      "Epoch [6/180],loss:0.5519\n",
      "Epoch [6/181],loss:2.6535\n",
      "Epoch [6/182],loss:0.7545\n",
      "Epoch [6/183],loss:0.4106\n",
      "Epoch [6/184],loss:0.2747\n",
      "Epoch [6/185],loss:1.2175\n",
      "Epoch [6/186],loss:0.8378\n",
      "Epoch [6/187],loss:1.0074\n",
      "Epoch [6/188],loss:1.6310\n",
      "Epoch [6/189],loss:0.1662\n",
      "Epoch [6/190],loss:1.1565\n",
      "Epoch [6/191],loss:0.3043\n",
      "Epoch [6/192],loss:0.0830\n",
      "Epoch [6/193],loss:0.4973\n",
      "Epoch [6/194],loss:1.1898\n",
      "Epoch [6/195],loss:1.0353\n",
      "Epoch [6/196],loss:0.8622\n",
      "Epoch [6/197],loss:0.6010\n",
      "Epoch [6/198],loss:0.8076\n",
      "Epoch [6/199],loss:1.0043\n",
      "Epoch [6/200],loss:1.1238\n",
      "Epoch [7/1],loss:0.1251\n",
      "Epoch [7/2],loss:0.4919\n",
      "Epoch [7/3],loss:0.3217\n",
      "Epoch [7/4],loss:0.7504\n",
      "Epoch [7/5],loss:0.6275\n",
      "Epoch [7/6],loss:0.7363\n",
      "Epoch [7/7],loss:1.1633\n",
      "Epoch [7/8],loss:0.3579\n",
      "Epoch [7/9],loss:0.4458\n",
      "Epoch [7/10],loss:0.4201\n",
      "Epoch [7/11],loss:0.7378\n",
      "Epoch [7/12],loss:1.4131\n",
      "Epoch [7/13],loss:0.6321\n",
      "Epoch [7/14],loss:0.5135\n",
      "Epoch [7/15],loss:1.5065\n",
      "Epoch [7/16],loss:0.7199\n",
      "Epoch [7/17],loss:0.9740\n",
      "Epoch [7/18],loss:0.7865\n",
      "Epoch [7/19],loss:0.7965\n",
      "Epoch [7/20],loss:0.9345\n",
      "Epoch [7/21],loss:1.1888\n",
      "Epoch [7/22],loss:1.1555\n",
      "Epoch [7/23],loss:0.0590\n",
      "Epoch [7/24],loss:0.7118\n",
      "Epoch [7/25],loss:1.3897\n",
      "Epoch [7/26],loss:0.2390\n",
      "Epoch [7/27],loss:1.0051\n",
      "Epoch [7/28],loss:0.5186\n",
      "Epoch [7/29],loss:0.7440\n",
      "Epoch [7/30],loss:0.5219\n",
      "Epoch [7/31],loss:0.2632\n",
      "Epoch [7/32],loss:0.2072\n",
      "Epoch [7/33],loss:0.9824\n",
      "Epoch [7/34],loss:1.9191\n",
      "Epoch [7/35],loss:0.1916\n",
      "Epoch [7/36],loss:0.7280\n",
      "Epoch [7/37],loss:0.8172\n",
      "Epoch [7/38],loss:0.2433\n",
      "Epoch [7/39],loss:1.0467\n",
      "Epoch [7/40],loss:0.5367\n",
      "Epoch [7/41],loss:0.5829\n",
      "Epoch [7/42],loss:0.5093\n",
      "Epoch [7/43],loss:0.1942\n",
      "Epoch [7/44],loss:0.1989\n",
      "Epoch [7/45],loss:0.7658\n",
      "Epoch [7/46],loss:0.8539\n",
      "Epoch [7/47],loss:0.5355\n",
      "Epoch [7/48],loss:0.1462\n",
      "Epoch [7/49],loss:0.5099\n",
      "Epoch [7/50],loss:1.0632\n",
      "Epoch [7/51],loss:0.7765\n",
      "Epoch [7/52],loss:0.9430\n",
      "Epoch [7/53],loss:0.6568\n",
      "Epoch [7/54],loss:0.3896\n",
      "Epoch [7/55],loss:0.9196\n",
      "Epoch [7/56],loss:0.3314\n",
      "Epoch [7/57],loss:0.4630\n",
      "Epoch [7/58],loss:1.3406\n",
      "Epoch [7/59],loss:0.1643\n",
      "Epoch [7/60],loss:0.1237\n",
      "Epoch [7/61],loss:0.1745\n",
      "Epoch [7/62],loss:0.8980\n",
      "Epoch [7/63],loss:0.2574\n",
      "Epoch [7/64],loss:0.7480\n",
      "Epoch [7/65],loss:1.0290\n",
      "Epoch [7/66],loss:1.3351\n",
      "Epoch [7/67],loss:0.9862\n",
      "Epoch [7/68],loss:0.6409\n",
      "Epoch [7/69],loss:1.5013\n",
      "Epoch [7/70],loss:3.8916\n",
      "Epoch [7/71],loss:0.7662\n",
      "Epoch [7/72],loss:0.4173\n",
      "Epoch [7/73],loss:0.8314\n",
      "Epoch [7/74],loss:0.1509\n",
      "Epoch [7/75],loss:0.1270\n",
      "Epoch [7/76],loss:0.8698\n",
      "Epoch [7/77],loss:0.9529\n",
      "Epoch [7/78],loss:1.2312\n",
      "Epoch [7/79],loss:1.3202\n",
      "Epoch [7/80],loss:0.7292\n",
      "Epoch [7/81],loss:0.3142\n",
      "Epoch [7/82],loss:1.3792\n",
      "Epoch [7/83],loss:0.6406\n",
      "Epoch [7/84],loss:1.4058\n",
      "Epoch [7/85],loss:0.8888\n",
      "Epoch [7/86],loss:0.9810\n",
      "Epoch [7/87],loss:0.2458\n",
      "Epoch [7/88],loss:0.2510\n",
      "Epoch [7/89],loss:0.3619\n",
      "Epoch [7/90],loss:0.4923\n",
      "Epoch [7/91],loss:1.5282\n",
      "Epoch [7/92],loss:0.3927\n",
      "Epoch [7/93],loss:0.4403\n",
      "Epoch [7/94],loss:1.1407\n",
      "Epoch [7/95],loss:0.1269\n",
      "Epoch [7/96],loss:0.3777\n",
      "Epoch [7/97],loss:0.1678\n",
      "Epoch [7/98],loss:0.1269\n",
      "Epoch [7/99],loss:0.1994\n",
      "Epoch [7/100],loss:1.3548\n",
      "Epoch [7/101],loss:0.1637\n",
      "Epoch [7/102],loss:0.8988\n",
      "Epoch [7/103],loss:0.7960\n",
      "Epoch [7/104],loss:1.1027\n",
      "Epoch [7/105],loss:0.1382\n",
      "Epoch [7/106],loss:0.2494\n",
      "Epoch [7/107],loss:0.9354\n",
      "Epoch [7/108],loss:1.0183\n",
      "Epoch [7/109],loss:1.1002\n",
      "Epoch [7/110],loss:0.2525\n",
      "Epoch [7/111],loss:0.7666\n",
      "Epoch [7/112],loss:0.8578\n",
      "Epoch [7/113],loss:0.3782\n",
      "Epoch [7/114],loss:0.8843\n",
      "Epoch [7/115],loss:0.3481\n",
      "Epoch [7/116],loss:3.2901\n",
      "Epoch [7/117],loss:0.8006\n",
      "Epoch [7/118],loss:0.1467\n",
      "Epoch [7/119],loss:0.1983\n",
      "Epoch [7/120],loss:0.1624\n",
      "Epoch [7/121],loss:0.7244\n",
      "Epoch [7/122],loss:0.7202\n",
      "Epoch [7/123],loss:0.3232\n",
      "Epoch [7/124],loss:0.7757\n",
      "Epoch [7/125],loss:0.6553\n",
      "Epoch [7/126],loss:0.7458\n",
      "Epoch [7/127],loss:0.8728\n",
      "Epoch [7/128],loss:0.1694\n",
      "Epoch [7/129],loss:1.6583\n",
      "Epoch [7/130],loss:0.8698\n",
      "Epoch [7/131],loss:0.4335\n",
      "Epoch [7/132],loss:1.0206\n",
      "Epoch [7/133],loss:0.2392\n",
      "Epoch [7/134],loss:0.1831\n",
      "Epoch [7/135],loss:0.2721\n",
      "Epoch [7/136],loss:0.7075\n",
      "Epoch [7/137],loss:0.3085\n",
      "Epoch [7/138],loss:0.0922\n",
      "Epoch [7/139],loss:0.2516\n",
      "Epoch [7/140],loss:0.1778\n",
      "Epoch [7/141],loss:0.4768\n",
      "Epoch [7/142],loss:3.3988\n",
      "Epoch [7/143],loss:0.8303\n",
      "Epoch [7/144],loss:0.7621\n",
      "Epoch [7/145],loss:2.1406\n",
      "Epoch [7/146],loss:3.1798\n",
      "Epoch [7/147],loss:0.3138\n",
      "Epoch [7/148],loss:0.7526\n",
      "Epoch [7/149],loss:0.4472\n",
      "Epoch [7/150],loss:1.2912\n",
      "Epoch [7/151],loss:0.2514\n",
      "Epoch [7/152],loss:0.4478\n",
      "Epoch [7/153],loss:1.2788\n",
      "Epoch [7/154],loss:0.9195\n",
      "Epoch [7/155],loss:0.8525\n",
      "Epoch [7/156],loss:0.3224\n",
      "Epoch [7/157],loss:0.2471\n",
      "Epoch [7/158],loss:0.8160\n",
      "Epoch [7/159],loss:0.5241\n",
      "Epoch [7/160],loss:0.4932\n",
      "Epoch [7/161],loss:1.4330\n",
      "Epoch [7/162],loss:2.0505\n",
      "Epoch [7/163],loss:1.3900\n",
      "Epoch [7/164],loss:1.5076\n",
      "Epoch [7/165],loss:0.1260\n",
      "Epoch [7/166],loss:0.2244\n",
      "Epoch [7/167],loss:3.1878\n",
      "Epoch [7/168],loss:0.8419\n",
      "Epoch [7/169],loss:0.7817\n",
      "Epoch [7/170],loss:0.5321\n",
      "Epoch [7/171],loss:0.8730\n",
      "Epoch [7/172],loss:0.2716\n",
      "Epoch [7/173],loss:1.4930\n",
      "Epoch [7/174],loss:0.9239\n",
      "Epoch [7/175],loss:0.3857\n",
      "Epoch [7/176],loss:0.3418\n",
      "Epoch [7/177],loss:0.7245\n",
      "Epoch [7/178],loss:0.8872\n",
      "Epoch [7/179],loss:0.1278\n",
      "Epoch [7/180],loss:0.3926\n",
      "Epoch [7/181],loss:2.7674\n",
      "Epoch [7/182],loss:0.4712\n",
      "Epoch [7/183],loss:0.1139\n",
      "Epoch [7/184],loss:0.3082\n",
      "Epoch [7/185],loss:0.9166\n",
      "Epoch [7/186],loss:0.6925\n",
      "Epoch [7/187],loss:0.8657\n",
      "Epoch [7/188],loss:1.4723\n",
      "Epoch [7/189],loss:0.1097\n",
      "Epoch [7/190],loss:1.0821\n",
      "Epoch [7/191],loss:0.0950\n",
      "Epoch [7/192],loss:0.0188\n",
      "Epoch [7/193],loss:0.2827\n",
      "Epoch [7/194],loss:0.8042\n",
      "Epoch [7/195],loss:0.8324\n",
      "Epoch [7/196],loss:0.7037\n",
      "Epoch [7/197],loss:0.5776\n",
      "Epoch [7/198],loss:0.6397\n",
      "Epoch [7/199],loss:0.9135\n",
      "Epoch [7/200],loss:1.0351\n",
      "Epoch [8/1],loss:0.0454\n",
      "Epoch [8/2],loss:0.5322\n",
      "Epoch [8/3],loss:0.4058\n",
      "Epoch [8/4],loss:0.5938\n",
      "Epoch [8/5],loss:0.6481\n",
      "Epoch [8/6],loss:0.6301\n",
      "Epoch [8/7],loss:1.2882\n",
      "Epoch [8/8],loss:0.2838\n",
      "Epoch [8/9],loss:0.3687\n",
      "Epoch [8/10],loss:0.4059\n",
      "Epoch [8/11],loss:0.6502\n",
      "Epoch [8/12],loss:1.2568\n",
      "Epoch [8/13],loss:0.4413\n",
      "Epoch [8/14],loss:0.4902\n",
      "Epoch [8/15],loss:1.2089\n",
      "Epoch [8/16],loss:0.5952\n",
      "Epoch [8/17],loss:0.6097\n",
      "Epoch [8/18],loss:0.5622\n",
      "Epoch [8/19],loss:0.6575\n",
      "Epoch [8/20],loss:0.8353\n",
      "Epoch [8/21],loss:0.7877\n",
      "Epoch [8/22],loss:1.1385\n",
      "Epoch [8/23],loss:0.0184\n",
      "Epoch [8/24],loss:0.6078\n",
      "Epoch [8/25],loss:1.2609\n",
      "Epoch [8/26],loss:0.0629\n",
      "Epoch [8/27],loss:0.9134\n",
      "Epoch [8/28],loss:0.5360\n",
      "Epoch [8/29],loss:0.7163\n",
      "Epoch [8/30],loss:0.4459\n",
      "Epoch [8/31],loss:0.2639\n",
      "Epoch [8/32],loss:0.2178\n",
      "Epoch [8/33],loss:0.9003\n",
      "Epoch [8/34],loss:1.8016\n",
      "Epoch [8/35],loss:0.2070\n",
      "Epoch [8/36],loss:0.5700\n",
      "Epoch [8/37],loss:0.8311\n",
      "Epoch [8/38],loss:0.1013\n",
      "Epoch [8/39],loss:1.0805\n",
      "Epoch [8/40],loss:0.5611\n",
      "Epoch [8/41],loss:0.5127\n",
      "Epoch [8/42],loss:0.5399\n",
      "Epoch [8/43],loss:0.1975\n",
      "Epoch [8/44],loss:0.2182\n",
      "Epoch [8/45],loss:0.8501\n",
      "Epoch [8/46],loss:0.7558\n",
      "Epoch [8/47],loss:0.4291\n",
      "Epoch [8/48],loss:0.0684\n",
      "Epoch [8/49],loss:0.3778\n",
      "Epoch [8/50],loss:1.0450\n",
      "Epoch [8/51],loss:0.9027\n",
      "Epoch [8/52],loss:0.8326\n",
      "Epoch [8/53],loss:0.6416\n",
      "Epoch [8/54],loss:0.2568\n",
      "Epoch [8/55],loss:0.8251\n",
      "Epoch [8/56],loss:0.2107\n",
      "Epoch [8/57],loss:0.2354\n",
      "Epoch [8/58],loss:1.4279\n",
      "Epoch [8/59],loss:0.0740\n",
      "Epoch [8/60],loss:0.1146\n",
      "Epoch [8/61],loss:0.0708\n",
      "Epoch [8/62],loss:0.7761\n",
      "Epoch [8/63],loss:0.1648\n",
      "Epoch [8/64],loss:0.4708\n",
      "Epoch [8/65],loss:0.8265\n",
      "Epoch [8/66],loss:1.1834\n",
      "Epoch [8/67],loss:0.9847\n",
      "Epoch [8/68],loss:0.4818\n",
      "Epoch [8/69],loss:1.1868\n",
      "Epoch [8/70],loss:4.2333\n",
      "Epoch [8/71],loss:0.6321\n",
      "Epoch [8/72],loss:0.1876\n",
      "Epoch [8/73],loss:0.6321\n",
      "Epoch [8/74],loss:0.0952\n",
      "Epoch [8/75],loss:0.1176\n",
      "Epoch [8/76],loss:0.6944\n",
      "Epoch [8/77],loss:0.7121\n",
      "Epoch [8/78],loss:1.2791\n",
      "Epoch [8/79],loss:1.3364\n",
      "Epoch [8/80],loss:0.7771\n",
      "Epoch [8/81],loss:0.3331\n",
      "Epoch [8/82],loss:1.3627\n",
      "Epoch [8/83],loss:0.5980\n",
      "Epoch [8/84],loss:1.8651\n",
      "Epoch [8/85],loss:0.9534\n",
      "Epoch [8/86],loss:0.8373\n",
      "Epoch [8/87],loss:0.2534\n",
      "Epoch [8/88],loss:0.1341\n",
      "Epoch [8/89],loss:0.3973\n",
      "Epoch [8/90],loss:0.3630\n",
      "Epoch [8/91],loss:1.5094\n",
      "Epoch [8/92],loss:0.2228\n",
      "Epoch [8/93],loss:0.5021\n",
      "Epoch [8/94],loss:1.3804\n",
      "Epoch [8/95],loss:0.0326\n",
      "Epoch [8/96],loss:0.2392\n",
      "Epoch [8/97],loss:0.0373\n",
      "Epoch [8/98],loss:0.0324\n",
      "Epoch [8/99],loss:0.2228\n",
      "Epoch [8/100],loss:1.2774\n",
      "Epoch [8/101],loss:0.1639\n",
      "Epoch [8/102],loss:0.8416\n",
      "Epoch [8/103],loss:0.6920\n",
      "Epoch [8/104],loss:0.7715\n",
      "Epoch [8/105],loss:0.0629\n",
      "Epoch [8/106],loss:0.0854\n",
      "Epoch [8/107],loss:0.8210\n",
      "Epoch [8/108],loss:1.1460\n",
      "Epoch [8/109],loss:1.0532\n",
      "Epoch [8/110],loss:0.2648\n",
      "Epoch [8/111],loss:0.6948\n",
      "Epoch [8/112],loss:0.6581\n",
      "Epoch [8/113],loss:0.1735\n",
      "Epoch [8/114],loss:0.8219\n",
      "Epoch [8/115],loss:0.2414\n",
      "Epoch [8/116],loss:3.3776\n",
      "Epoch [8/117],loss:0.6940\n",
      "Epoch [8/118],loss:0.0666\n",
      "Epoch [8/119],loss:0.1921\n",
      "Epoch [8/120],loss:0.1505\n",
      "Epoch [8/121],loss:0.6510\n",
      "Epoch [8/122],loss:0.6265\n",
      "Epoch [8/123],loss:0.2372\n",
      "Epoch [8/124],loss:0.6594\n",
      "Epoch [8/125],loss:0.5355\n",
      "Epoch [8/126],loss:0.7139\n",
      "Epoch [8/127],loss:0.7727\n",
      "Epoch [8/128],loss:0.1105\n",
      "Epoch [8/129],loss:1.6918\n",
      "Epoch [8/130],loss:0.7834\n",
      "Epoch [8/131],loss:0.3331\n",
      "Epoch [8/132],loss:0.9069\n",
      "Epoch [8/133],loss:0.1957\n",
      "Epoch [8/134],loss:0.1077\n",
      "Epoch [8/135],loss:0.2502\n",
      "Epoch [8/136],loss:0.5050\n",
      "Epoch [8/137],loss:0.2941\n",
      "Epoch [8/138],loss:0.0635\n",
      "Epoch [8/139],loss:0.1673\n",
      "Epoch [8/140],loss:0.1750\n",
      "Epoch [8/141],loss:0.2804\n",
      "Epoch [8/142],loss:3.2272\n",
      "Epoch [8/143],loss:0.7176\n",
      "Epoch [8/144],loss:0.4495\n",
      "Epoch [8/145],loss:2.1455\n",
      "Epoch [8/146],loss:3.3804\n",
      "Epoch [8/147],loss:0.2247\n",
      "Epoch [8/148],loss:0.6500\n",
      "Epoch [8/149],loss:0.4584\n",
      "Epoch [8/150],loss:1.2807\n",
      "Epoch [8/151],loss:0.2482\n",
      "Epoch [8/152],loss:0.3679\n",
      "Epoch [8/153],loss:1.2302\n",
      "Epoch [8/154],loss:1.0077\n",
      "Epoch [8/155],loss:0.8316\n",
      "Epoch [8/156],loss:0.2418\n",
      "Epoch [8/157],loss:0.1210\n",
      "Epoch [8/158],loss:0.7550\n",
      "Epoch [8/159],loss:0.4177\n",
      "Epoch [8/160],loss:0.3995\n",
      "Epoch [8/161],loss:1.5390\n",
      "Epoch [8/162],loss:2.4687\n",
      "Epoch [8/163],loss:1.4186\n",
      "Epoch [8/164],loss:1.4282\n",
      "Epoch [8/165],loss:0.0541\n",
      "Epoch [8/166],loss:0.2094\n",
      "Epoch [8/167],loss:3.2710\n",
      "Epoch [8/168],loss:0.7484\n",
      "Epoch [8/169],loss:0.7039\n",
      "Epoch [8/170],loss:0.4152\n",
      "Epoch [8/171],loss:0.8228\n",
      "Epoch [8/172],loss:0.2453\n",
      "Epoch [8/173],loss:1.4119\n",
      "Epoch [8/174],loss:0.8539\n",
      "Epoch [8/175],loss:0.2784\n",
      "Epoch [8/176],loss:0.2550\n",
      "Epoch [8/177],loss:0.6660\n",
      "Epoch [8/178],loss:0.8290\n",
      "Epoch [8/179],loss:0.0712\n",
      "Epoch [8/180],loss:0.2823\n",
      "Epoch [8/181],loss:2.7974\n",
      "Epoch [8/182],loss:0.3078\n",
      "Epoch [8/183],loss:0.0508\n",
      "Epoch [8/184],loss:0.2917\n",
      "Epoch [8/185],loss:0.7692\n",
      "Epoch [8/186],loss:0.6309\n",
      "Epoch [8/187],loss:0.8262\n",
      "Epoch [8/188],loss:1.4679\n",
      "Epoch [8/189],loss:0.0954\n",
      "Epoch [8/190],loss:0.9504\n",
      "Epoch [8/191],loss:0.0562\n",
      "Epoch [8/192],loss:0.0090\n",
      "Epoch [8/193],loss:0.2272\n",
      "Epoch [8/194],loss:0.4687\n",
      "Epoch [8/195],loss:0.7226\n",
      "Epoch [8/196],loss:0.6380\n",
      "Epoch [8/197],loss:0.5630\n",
      "Epoch [8/198],loss:0.5768\n",
      "Epoch [8/199],loss:0.8905\n",
      "Epoch [8/200],loss:1.0044\n",
      "Epoch [9/1],loss:0.0260\n",
      "Epoch [9/2],loss:0.5254\n",
      "Epoch [9/3],loss:0.4165\n",
      "Epoch [9/4],loss:0.5223\n",
      "Epoch [9/5],loss:0.6563\n",
      "Epoch [9/6],loss:0.6224\n",
      "Epoch [9/7],loss:1.3433\n",
      "Epoch [9/8],loss:0.2040\n",
      "Epoch [9/9],loss:0.3188\n",
      "Epoch [9/10],loss:0.3963\n",
      "Epoch [9/11],loss:0.6346\n",
      "Epoch [9/12],loss:1.1672\n",
      "Epoch [9/13],loss:0.3372\n",
      "Epoch [9/14],loss:0.4833\n",
      "Epoch [9/15],loss:1.0139\n",
      "Epoch [9/16],loss:0.5427\n",
      "Epoch [9/17],loss:0.4322\n",
      "Epoch [9/18],loss:0.3824\n",
      "Epoch [9/19],loss:0.5923\n",
      "Epoch [9/20],loss:0.7952\n",
      "Epoch [9/21],loss:0.5612\n",
      "Epoch [9/22],loss:1.1793\n",
      "Epoch [9/23],loss:0.0087\n",
      "Epoch [9/24],loss:0.5636\n",
      "Epoch [9/25],loss:1.2261\n",
      "Epoch [9/26],loss:0.0254\n",
      "Epoch [9/27],loss:0.8744\n",
      "Epoch [9/28],loss:0.5522\n",
      "Epoch [9/29],loss:0.7263\n",
      "Epoch [9/30],loss:0.3389\n",
      "Epoch [9/31],loss:0.2547\n",
      "Epoch [9/32],loss:0.2066\n",
      "Epoch [9/33],loss:0.8724\n",
      "Epoch [9/34],loss:1.6013\n",
      "Epoch [9/35],loss:0.2000\n",
      "Epoch [9/36],loss:0.4600\n",
      "Epoch [9/37],loss:0.7742\n",
      "Epoch [9/38],loss:0.0508\n",
      "Epoch [9/39],loss:1.0350\n",
      "Epoch [9/40],loss:0.5633\n",
      "Epoch [9/41],loss:0.4380\n",
      "Epoch [9/42],loss:0.5452\n",
      "Epoch [9/43],loss:0.1782\n",
      "Epoch [9/44],loss:0.2120\n",
      "Epoch [9/45],loss:0.9001\n",
      "Epoch [9/46],loss:0.7246\n",
      "Epoch [9/47],loss:0.3582\n",
      "Epoch [9/48],loss:0.0397\n",
      "Epoch [9/49],loss:0.2836\n",
      "Epoch [9/50],loss:1.0089\n",
      "Epoch [9/51],loss:0.9641\n",
      "Epoch [9/52],loss:0.7903\n",
      "Epoch [9/53],loss:0.5584\n",
      "Epoch [9/54],loss:0.2008\n",
      "Epoch [9/55],loss:0.7653\n",
      "Epoch [9/56],loss:0.1543\n",
      "Epoch [9/57],loss:0.1294\n",
      "Epoch [9/58],loss:1.3416\n",
      "Epoch [9/59],loss:0.0485\n",
      "Epoch [9/60],loss:0.1042\n",
      "Epoch [9/61],loss:0.0374\n",
      "Epoch [9/62],loss:0.7066\n",
      "Epoch [9/63],loss:0.1219\n",
      "Epoch [9/64],loss:0.3485\n",
      "Epoch [9/65],loss:0.7321\n",
      "Epoch [9/66],loss:1.0555\n",
      "Epoch [9/67],loss:0.9788\n",
      "Epoch [9/68],loss:0.3750\n",
      "Epoch [9/69],loss:0.9268\n",
      "Epoch [9/70],loss:4.3709\n",
      "Epoch [9/71],loss:0.5777\n",
      "Epoch [9/72],loss:0.1046\n",
      "Epoch [9/73],loss:0.4726\n",
      "Epoch [9/74],loss:0.0773\n",
      "Epoch [9/75],loss:0.1054\n",
      "Epoch [9/76],loss:0.6546\n",
      "Epoch [9/77],loss:0.5069\n",
      "Epoch [9/78],loss:1.1303\n",
      "Epoch [9/79],loss:1.3562\n",
      "Epoch [9/80],loss:0.7552\n",
      "Epoch [9/81],loss:0.3322\n",
      "Epoch [9/82],loss:1.3599\n",
      "Epoch [9/83],loss:0.5538\n",
      "Epoch [9/84],loss:2.0120\n",
      "Epoch [9/85],loss:0.9614\n",
      "Epoch [9/86],loss:0.7516\n",
      "Epoch [9/87],loss:0.2526\n",
      "Epoch [9/88],loss:0.0821\n",
      "Epoch [9/89],loss:0.4048\n",
      "Epoch [9/90],loss:0.2741\n",
      "Epoch [9/91],loss:1.4913\n",
      "Epoch [9/92],loss:0.1550\n",
      "Epoch [9/93],loss:0.5325\n",
      "Epoch [9/94],loss:1.4976\n",
      "Epoch [9/95],loss:0.0121\n",
      "Epoch [9/96],loss:0.1573\n",
      "Epoch [9/97],loss:0.0128\n",
      "Epoch [9/98],loss:0.0118\n",
      "Epoch [9/99],loss:0.2353\n",
      "Epoch [9/100],loss:1.2115\n",
      "Epoch [9/101],loss:0.1627\n",
      "Epoch [9/102],loss:0.7987\n",
      "Epoch [9/103],loss:0.6332\n",
      "Epoch [9/104],loss:0.5637\n",
      "Epoch [9/105],loss:0.0328\n",
      "Epoch [9/106],loss:0.0355\n",
      "Epoch [9/107],loss:0.7674\n",
      "Epoch [9/108],loss:1.2662\n",
      "Epoch [9/109],loss:1.0839\n",
      "Epoch [9/110],loss:0.2777\n",
      "Epoch [9/111],loss:0.6479\n",
      "Epoch [9/112],loss:0.5226\n",
      "Epoch [9/113],loss:0.0791\n",
      "Epoch [9/114],loss:0.7703\n",
      "Epoch [9/115],loss:0.1816\n",
      "Epoch [9/116],loss:3.3309\n",
      "Epoch [9/117],loss:0.6382\n",
      "Epoch [9/118],loss:0.0324\n",
      "Epoch [9/119],loss:0.1877\n",
      "Epoch [9/120],loss:0.1437\n",
      "Epoch [9/121],loss:0.6120\n",
      "Epoch [9/122],loss:0.5685\n",
      "Epoch [9/123],loss:0.2123\n",
      "Epoch [9/124],loss:0.5823\n",
      "Epoch [9/125],loss:0.4737\n",
      "Epoch [9/126],loss:0.7147\n",
      "Epoch [9/127],loss:0.7238\n",
      "Epoch [9/128],loss:0.0633\n",
      "Epoch [9/129],loss:1.7149\n",
      "Epoch [9/130],loss:0.7072\n",
      "Epoch [9/131],loss:0.2604\n",
      "Epoch [9/132],loss:0.8157\n",
      "Epoch [9/133],loss:0.1554\n",
      "Epoch [9/134],loss:0.0646\n",
      "Epoch [9/135],loss:0.2014\n",
      "Epoch [9/136],loss:0.3992\n",
      "Epoch [9/137],loss:0.2876\n",
      "Epoch [9/138],loss:0.0402\n",
      "Epoch [9/139],loss:0.1356\n",
      "Epoch [9/140],loss:0.1687\n",
      "Epoch [9/141],loss:0.2022\n",
      "Epoch [9/142],loss:2.9725\n",
      "Epoch [9/143],loss:0.6376\n",
      "Epoch [9/144],loss:0.3008\n",
      "Epoch [9/145],loss:2.1814\n",
      "Epoch [9/146],loss:3.4987\n",
      "Epoch [9/147],loss:0.1881\n",
      "Epoch [9/148],loss:0.5882\n",
      "Epoch [9/149],loss:0.4646\n",
      "Epoch [9/150],loss:1.2858\n",
      "Epoch [9/151],loss:0.2491\n",
      "Epoch [9/152],loss:0.3430\n",
      "Epoch [9/153],loss:1.1712\n",
      "Epoch [9/154],loss:1.0730\n",
      "Epoch [9/155],loss:0.7938\n",
      "Epoch [9/156],loss:0.1901\n",
      "Epoch [9/157],loss:0.0699\n",
      "Epoch [9/158],loss:0.7328\n",
      "Epoch [9/159],loss:0.3488\n",
      "Epoch [9/160],loss:0.3389\n",
      "Epoch [9/161],loss:1.5535\n",
      "Epoch [9/162],loss:2.7225\n",
      "Epoch [9/163],loss:1.4288\n",
      "Epoch [9/164],loss:1.2953\n",
      "Epoch [9/165],loss:0.0281\n",
      "Epoch [9/166],loss:0.2079\n",
      "Epoch [9/167],loss:3.2030\n",
      "Epoch [9/168],loss:0.6787\n",
      "Epoch [9/169],loss:0.6594\n",
      "Epoch [9/170],loss:0.3273\n",
      "Epoch [9/171],loss:0.7928\n",
      "Epoch [9/172],loss:0.2397\n",
      "Epoch [9/173],loss:1.1910\n",
      "Epoch [9/174],loss:0.7853\n",
      "Epoch [9/175],loss:0.2220\n",
      "Epoch [9/176],loss:0.2178\n",
      "Epoch [9/177],loss:0.6273\n",
      "Epoch [9/178],loss:0.7784\n",
      "Epoch [9/179],loss:0.0445\n",
      "Epoch [9/180],loss:0.2027\n",
      "Epoch [9/181],loss:2.7389\n",
      "Epoch [9/182],loss:0.2032\n",
      "Epoch [9/183],loss:0.0280\n",
      "Epoch [9/184],loss:0.2689\n",
      "Epoch [9/185],loss:0.6741\n",
      "Epoch [9/186],loss:0.5933\n",
      "Epoch [9/187],loss:0.8287\n",
      "Epoch [9/188],loss:1.4839\n",
      "Epoch [9/189],loss:0.0788\n",
      "Epoch [9/190],loss:0.8410\n",
      "Epoch [9/191],loss:0.0414\n",
      "Epoch [9/192],loss:0.0054\n",
      "Epoch [9/193],loss:0.1972\n",
      "Epoch [9/194],loss:0.3020\n",
      "Epoch [9/195],loss:0.6505\n",
      "Epoch [9/196],loss:0.6011\n",
      "Epoch [9/197],loss:0.5488\n",
      "Epoch [9/198],loss:0.5500\n",
      "Epoch [9/199],loss:0.8731\n",
      "Epoch [9/200],loss:0.9862\n",
      "Epoch [10/1],loss:0.0179\n",
      "Epoch [10/2],loss:0.5016\n",
      "Epoch [10/3],loss:0.4051\n",
      "Epoch [10/4],loss:0.4759\n",
      "Epoch [10/5],loss:0.6511\n",
      "Epoch [10/6],loss:0.6258\n",
      "Epoch [10/7],loss:1.3386\n",
      "Epoch [10/8],loss:0.1743\n",
      "Epoch [10/9],loss:0.2995\n",
      "Epoch [10/10],loss:0.3854\n",
      "Epoch [10/11],loss:0.6318\n",
      "Epoch [10/12],loss:1.1025\n",
      "Epoch [10/13],loss:0.2780\n",
      "Epoch [10/14],loss:0.4809\n",
      "Epoch [10/15],loss:0.9118\n",
      "Epoch [10/16],loss:0.5101\n",
      "Epoch [10/17],loss:0.3239\n",
      "Epoch [10/18],loss:0.2812\n",
      "Epoch [10/19],loss:0.5440\n",
      "Epoch [10/20],loss:0.7666\n",
      "Epoch [10/21],loss:0.4441\n",
      "Epoch [10/22],loss:1.1716\n",
      "Epoch [10/23],loss:0.0050\n",
      "Epoch [10/24],loss:0.5302\n",
      "Epoch [10/25],loss:1.2116\n",
      "Epoch [10/26],loss:0.0133\n",
      "Epoch [10/27],loss:0.8292\n",
      "Epoch [10/28],loss:0.5862\n",
      "Epoch [10/29],loss:0.7254\n",
      "Epoch [10/30],loss:0.2549\n",
      "Epoch [10/31],loss:0.2541\n",
      "Epoch [10/32],loss:0.1946\n",
      "Epoch [10/33],loss:0.8242\n",
      "Epoch [10/34],loss:1.4023\n",
      "Epoch [10/35],loss:0.1915\n",
      "Epoch [10/36],loss:0.3789\n",
      "Epoch [10/37],loss:0.6997\n",
      "Epoch [10/38],loss:0.0286\n",
      "Epoch [10/39],loss:0.9317\n",
      "Epoch [10/40],loss:0.5666\n",
      "Epoch [10/41],loss:0.3774\n",
      "Epoch [10/42],loss:0.5454\n",
      "Epoch [10/43],loss:0.1587\n",
      "Epoch [10/44],loss:0.2011\n",
      "Epoch [10/45],loss:0.9653\n",
      "Epoch [10/46],loss:0.6912\n",
      "Epoch [10/47],loss:0.2997\n",
      "Epoch [10/48],loss:0.0246\n",
      "Epoch [10/49],loss:0.2233\n",
      "Epoch [10/50],loss:0.9642\n",
      "Epoch [10/51],loss:0.9033\n",
      "Epoch [10/52],loss:0.7420\n",
      "Epoch [10/53],loss:0.4634\n",
      "Epoch [10/54],loss:0.1637\n",
      "Epoch [10/55],loss:0.7675\n",
      "Epoch [10/56],loss:0.1117\n",
      "Epoch [10/57],loss:0.0805\n",
      "Epoch [10/58],loss:1.2085\n",
      "Epoch [10/59],loss:0.0346\n",
      "Epoch [10/60],loss:0.0951\n",
      "Epoch [10/61],loss:0.0222\n",
      "Epoch [10/62],loss:0.6575\n",
      "Epoch [10/63],loss:0.0928\n",
      "Epoch [10/64],loss:0.2946\n",
      "Epoch [10/65],loss:0.6822\n",
      "Epoch [10/66],loss:0.9425\n",
      "Epoch [10/67],loss:0.9821\n",
      "Epoch [10/68],loss:0.3036\n",
      "Epoch [10/69],loss:0.7174\n",
      "Epoch [10/70],loss:4.3897\n",
      "Epoch [10/71],loss:0.5487\n",
      "Epoch [10/72],loss:0.0639\n",
      "Epoch [10/73],loss:0.3392\n",
      "Epoch [10/74],loss:0.0721\n",
      "Epoch [10/75],loss:0.0915\n",
      "Epoch [10/76],loss:0.6428\n",
      "Epoch [10/77],loss:0.3374\n",
      "Epoch [10/78],loss:0.9529\n",
      "Epoch [10/79],loss:1.3525\n",
      "Epoch [10/80],loss:0.7144\n",
      "Epoch [10/81],loss:0.3212\n",
      "Epoch [10/82],loss:1.3727\n",
      "Epoch [10/83],loss:0.5249\n",
      "Epoch [10/84],loss:2.0880\n",
      "Epoch [10/85],loss:0.9357\n",
      "Epoch [10/86],loss:0.6832\n",
      "Epoch [10/87],loss:0.2461\n",
      "Epoch [10/88],loss:0.0532\n",
      "Epoch [10/89],loss:0.3970\n",
      "Epoch [10/90],loss:0.2133\n",
      "Epoch [10/91],loss:1.4936\n",
      "Epoch [10/92],loss:0.1214\n",
      "Epoch [10/93],loss:0.5328\n",
      "Epoch [10/94],loss:1.5185\n",
      "Epoch [10/95],loss:0.0055\n",
      "Epoch [10/96],loss:0.1030\n",
      "Epoch [10/97],loss:0.0059\n",
      "Epoch [10/98],loss:0.0054\n",
      "Epoch [10/99],loss:0.2352\n",
      "Epoch [10/100],loss:1.1599\n",
      "Epoch [10/101],loss:0.1568\n",
      "Epoch [10/102],loss:0.7645\n",
      "Epoch [10/103],loss:0.5910\n",
      "Epoch [10/104],loss:0.4323\n",
      "Epoch [10/105],loss:0.0194\n",
      "Epoch [10/106],loss:0.0181\n",
      "Epoch [10/107],loss:0.7658\n",
      "Epoch [10/108],loss:1.3139\n",
      "Epoch [10/109],loss:1.0951\n",
      "Epoch [10/110],loss:0.2851\n",
      "Epoch [10/111],loss:0.6149\n",
      "Epoch [10/112],loss:0.4362\n",
      "Epoch [10/113],loss:0.0399\n",
      "Epoch [10/114],loss:0.7146\n",
      "Epoch [10/115],loss:0.1392\n",
      "Epoch [10/116],loss:3.2399\n",
      "Epoch [10/117],loss:0.6040\n",
      "Epoch [10/118],loss:0.0167\n",
      "Epoch [10/119],loss:0.1844\n",
      "Epoch [10/120],loss:0.1391\n",
      "Epoch [10/121],loss:0.5899\n",
      "Epoch [10/122],loss:0.5140\n",
      "Epoch [10/123],loss:0.2040\n",
      "Epoch [10/124],loss:0.5240\n",
      "Epoch [10/125],loss:0.4280\n",
      "Epoch [10/126],loss:0.7158\n",
      "Epoch [10/127],loss:0.6810\n",
      "Epoch [10/128],loss:0.0344\n",
      "Epoch [10/129],loss:1.6942\n",
      "Epoch [10/130],loss:0.6431\n",
      "Epoch [10/131],loss:0.1930\n",
      "Epoch [10/132],loss:0.7544\n",
      "Epoch [10/133],loss:0.1179\n",
      "Epoch [10/134],loss:0.0391\n",
      "Epoch [10/135],loss:0.1501\n",
      "Epoch [10/136],loss:0.3348\n",
      "Epoch [10/137],loss:0.2864\n",
      "Epoch [10/138],loss:0.0235\n",
      "Epoch [10/139],loss:0.1200\n",
      "Epoch [10/140],loss:0.1591\n",
      "Epoch [10/141],loss:0.1618\n",
      "Epoch [10/142],loss:2.7035\n",
      "Epoch [10/143],loss:0.5767\n",
      "Epoch [10/144],loss:0.2164\n",
      "Epoch [10/145],loss:2.2306\n",
      "Epoch [10/146],loss:3.5682\n",
      "Epoch [10/147],loss:0.1678\n",
      "Epoch [10/148],loss:0.5470\n",
      "Epoch [10/149],loss:0.4657\n",
      "Epoch [10/150],loss:1.2872\n",
      "Epoch [10/151],loss:0.2489\n",
      "Epoch [10/152],loss:0.3396\n",
      "Epoch [10/153],loss:1.1153\n",
      "Epoch [10/154],loss:1.0947\n",
      "Epoch [10/155],loss:0.7559\n",
      "Epoch [10/156],loss:0.1501\n",
      "Epoch [10/157],loss:0.0427\n",
      "Epoch [10/158],loss:0.7249\n",
      "Epoch [10/159],loss:0.2960\n",
      "Epoch [10/160],loss:0.2918\n",
      "Epoch [10/161],loss:1.5296\n",
      "Epoch [10/162],loss:2.8835\n",
      "Epoch [10/163],loss:1.4388\n",
      "Epoch [10/164],loss:1.1479\n",
      "Epoch [10/165],loss:0.0160\n",
      "Epoch [10/166],loss:0.2130\n",
      "Epoch [10/167],loss:3.0546\n",
      "Epoch [10/168],loss:0.6223\n",
      "Epoch [10/169],loss:0.6308\n",
      "Epoch [10/170],loss:0.2606\n",
      "Epoch [10/171],loss:0.7679\n",
      "Epoch [10/172],loss:0.2452\n",
      "Epoch [10/173],loss:0.9622\n",
      "Epoch [10/174],loss:0.7114\n",
      "Epoch [10/175],loss:0.1829\n",
      "Epoch [10/176],loss:0.2045\n",
      "Epoch [10/177],loss:0.5976\n",
      "Epoch [10/178],loss:0.7168\n",
      "Epoch [10/179],loss:0.0302\n",
      "Epoch [10/180],loss:0.1439\n",
      "Epoch [10/181],loss:2.6452\n",
      "Epoch [10/182],loss:0.1354\n",
      "Epoch [10/183],loss:0.0166\n",
      "Epoch [10/184],loss:0.2458\n",
      "Epoch [10/185],loss:0.6042\n",
      "Epoch [10/186],loss:0.5650\n",
      "Epoch [10/187],loss:0.8339\n",
      "Epoch [10/188],loss:1.4991\n",
      "Epoch [10/189],loss:0.0629\n",
      "Epoch [10/190],loss:0.7710\n",
      "Epoch [10/191],loss:0.0291\n",
      "Epoch [10/192],loss:0.0034\n",
      "Epoch [10/193],loss:0.1667\n",
      "Epoch [10/194],loss:0.2150\n",
      "Epoch [10/195],loss:0.5945\n",
      "Epoch [10/196],loss:0.5745\n",
      "Epoch [10/197],loss:0.5418\n",
      "Epoch [10/198],loss:0.5417\n",
      "Epoch [10/199],loss:0.8314\n",
      "Epoch [10/200],loss:0.9684\n",
      "süre: 94.66741228103638\n"
     ]
    }
   ],
   "source": [
    "#tensorflowda fit metoduyla yaptıgımız işlem.\n",
    "\n",
    "start=time.time() # zamınımızı tutacak yapmasakta olur\n",
    "\n",
    "model=Net() # yukarda tanımladıgımız classı çağırıyoruz\n",
    "\n",
    "optimizer=torch.optim.Adamax(model.parameters(),lr=0.001) #optimizasyon fonksiyonumuzu belirliyoruz. İçerisine modelimizin parametrelerini ve learning rate değerimizi giriyoruzki ağırlıkları güncelleyebilsin.\n",
    "\n",
    "error=torch.nn.CrossEntropyLoss() #loss fonksiyonumuzu belirledik\n",
    "\n",
    "epoch = 10\n",
    "\n",
    "for j in range(epoch):\n",
    "    for i,(images,label) in enumerate (train_loader):\n",
    "\n",
    "        optimizer.zero_grad() # her bir epoch sonunda türev değerlini sıfırlıyor. Ağırlıklara göre her bir epocta yeni bir türev değeri hesaplıyor.\n",
    "        tahmin=model(images)\n",
    "        loss=error(tahmin,label)\n",
    "        loss.backward() # kayıp değerine göre geri yayılımı uyguluyoruz.\n",
    "        optimizer.step() #zero_grad, backward ve step fonksiyonları olmazla olmaz fonksiyonlar. step sonraki adıma geçmemizi sağlıyor.\n",
    "\n",
    "        print(\"Epoch [{}/{}],loss:{:.4f}\".format(j+1,i+1,loss.item()))\n",
    "end=time.time()\n",
    "print(\"süre:\",end-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dogruluk(loader,model):\n",
    "    num_correct=0\n",
    "    num_samples=0\n",
    "    model.eval()#modeli test edicez\n",
    "\n",
    "    with torch.no_grad(): #burda modelimizi eğitmediğimiz için türevleri hesaplatmıcaz\n",
    "        for x,y in loader:\n",
    "            tahmin=model(x)\n",
    "            _,pred=tahmin.max(1)\n",
    "            num_correct+=(pred==y).sum() #tahmin değerimizi y' ye eşitse correcti 1 artıracak\n",
    "            num_samples+=pred.size(0)\n",
    "            \n",
    "        print(f\"Got {num_correct}/{num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n",
    "        model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dogruluk:\n",
      "Got 154/200 with accuracy 77.00\n",
      "test dogruluk:\n",
      "Got 53/79 with accuracy 67.09\n"
     ]
    }
   ],
   "source": [
    "print(\"train dogruluk:\")\n",
    "dogruluk(train_loader,model)\n",
    "print(\"test dogruluk:\")\n",
    "dogruluk(test_loader,model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin Eğitimi ve Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100 loss: 1.431093454360962 accuracy: 48.10% Error: 51.90%\n",
      "Iteration: 200 loss: 0.9139726758003235 accuracy: 56.96% Error: 43.04%\n",
      "Iteration: 300 loss: 1.1586244106292725 accuracy: 62.03% Error: 37.97%\n",
      "Iteration: 400 loss: 0.09702415019273758 accuracy: 60.76% Error: 39.24%\n",
      "Iteration: 500 loss: 1.006575107574463 accuracy: 62.03% Error: 37.97%\n",
      "Iteration: 600 loss: 0.047033362090587616 accuracy: 58.23% Error: 41.77%\n",
      "Iteration: 700 loss: 1.1262098550796509 accuracy: 65.82% Error: 34.18%\n",
      "Iteration: 800 loss: 0.08997895568609238 accuracy: 62.03% Error: 37.97%\n",
      "Iteration: 900 loss: 0.5614885687828064 accuracy: 77.22% Error: 22.78%\n",
      "Iteration: 1000 loss: 0.08382895588874817 accuracy: 67.09% Error: 32.91%\n",
      "Iteration: 1100 loss: 0.3654977083206177 accuracy: 75.95% Error: 24.05%\n",
      "Iteration: 1200 loss: 0.015043382532894611 accuracy: 60.76% Error: 39.24%\n",
      "Iteration: 1300 loss: 0.2500057816505432 accuracy: 74.68% Error: 25.32%\n",
      "Iteration: 1400 loss: 0.21667613089084625 accuracy: 70.89% Error: 29.11%\n",
      "Iteration: 1500 loss: 0.3522079586982727 accuracy: 77.22% Error: 22.78%\n",
      "Iteration: 1600 loss: 0.012147023342549801 accuracy: 72.15% Error: 27.85%\n",
      "Iteration: 1700 loss: 0.2854798138141632 accuracy: 77.22% Error: 22.78%\n",
      "Iteration: 1800 loss: 0.0041315918788313866 accuracy: 73.42% Error: 26.58%\n",
      "Iteration: 1900 loss: 0.20730015635490417 accuracy: 77.22% Error: 22.78%\n",
      "Iteration: 2000 loss: 0.007748783566057682 accuracy: 81.01% Error: 18.99%\n",
      "süre: 163.14839887619019\n"
     ]
    }
   ],
   "source": [
    "# bu kısımda model eğitilirken aynı zamanda testide yaptıgımız kısımdır. Bu aşamayı kullanırken önceki iki aşamaya gerek kalmıyor.\n",
    "\n",
    "start=time.time() \n",
    "\n",
    "model=Net() \n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001) \n",
    "\n",
    "error=torch.nn.CrossEntropyLoss() \n",
    "\n",
    "epoch = 10\n",
    "\n",
    "kayıp=[] #loss bilgimizi eklicez\n",
    "count=0\n",
    "iterasyon=[] #iterasyonları buna eklicez\n",
    "for i in range(epoch):\n",
    "    for i,(images,label) in enumerate(train_loader):\n",
    "        tahmin=model(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss=error(tahmin,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        count+=1\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            total=0\n",
    "            correct=0\n",
    "            correct_hata=0\n",
    "            for image,labels in test_loader:\n",
    "                out=model(image)\n",
    "                pred=torch.max(out.data,1)[1]\n",
    "                total+=len(label)\n",
    "\n",
    "                correct+=(pred==labels).sum() #doğru sayımız\n",
    "                correct_hata+=(pred!=labels).sum() # yanlış sayımız\n",
    "            dogruluk=100*correct/float(total)\n",
    "            hata=100*correct_hata/float(total)\n",
    "\n",
    "            kayıp.append(loss.data)\n",
    "            iterasyon.append(count)\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            print('Iteration: {} loss: {} accuracy: {:.2f}% Error: {:.2f}%'.format(count,loss.data,dogruluk,hata))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "end=time.time()\n",
    "print(\"süre:\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"udemy1.pth\") #modeli kaydetme\n",
    "torch.save(model.state_dict(),\"udemy11.pth\") #modelin sadece ağırlıklarını kaydetme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=torch.load(\"udemy1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 4, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(8, 16, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (conv4): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (max): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (func): ELU(alpha=1.0)\n",
       "  (fc1): Linear(in_features=32, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (fc3): Linear(in_features=50, out_features=100, bias=True)\n",
       "  (fc4): Linear(in_features=100, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model11=Net() #ağırlıkları kullanarak laod etme (tekrar classımızı çağırıp eval ile modeli çağırıyoruz)\n",
    "model11.load_state_dict(torch.load(\"udemy11.pth\"))\n",
    "model11.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dogruluk:\n",
      "Got 179/200 with accuracy 89.50\n",
      "test dogruluk:\n",
      "Got 69/79 with accuracy 87.34\n"
     ]
    }
   ],
   "source": [
    "print(\"train dogruluk:\")\n",
    "dogruluk(train_loader,model1)\n",
    "print(\"test dogruluk:\")\n",
    "dogruluk(test_loader,model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6890cd249af4e4ffbb6e94abfb53100042eb61c81d00e1f1ac790c73285b1fdf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
