{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from skimage import io\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriyi Dahil Etme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class veri(Dataset): #dataset classı pytorch un veriyi eklemek için kullandırttığı bir classdır.\n",
    "    def __init__(self, csv_file, root_dir, transform=None): #csv_file fotograflarımızın adreslerinin yer aldığı dosyadır onun pathini vermemiz gerekiyor. root_dir fotograflarımızın oldugu klasörün adresidir\n",
    "        self.annotations=pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    def __getitem__(self, index):\n",
    "       img_path=os.path.join(self.root_dir,self.annotations.iloc[index,0])\n",
    "       image=io.imread(img_path)\n",
    "       y_label=torch.tensor(int(self.annotations.iloc[index,1]))\n",
    "       \n",
    "       if self.transform:\n",
    "              image=self.transform(image)\n",
    "              return (image,y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriyi Hazırlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=veri(csv_file=\"D:\\\\udemy_data\\\\f1_classification\\\\f111.csv\",root_dir=\"D:\\\\udemy_data\\\\f1_classification\",\n",
    "transform=torchvision.transforms.Compose([ #compose metodu birden fazla transform işlemini tek seferde yapmamıza olanak tanır.\n",
    "    transforms.ToTensor(), #tensore cevirmemizi sağlar verimizi\n",
    "    transforms.Resize(size=(28,28)),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,test_set=torch.utils.data.random_split(dataset,[200,79]) # verimizin 200 ü train geri kalan 79 tanesi test için ayrıldı\n",
    "train_loader=DataLoader(dataset=train_set,batch_size=1,shuffle=False)\n",
    "test_loader=DataLoader(dataset=test_set,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriyi Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mercedes\n",
      "torch.Size([1, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "batch_size=1\n",
    "classes=[\"Ferrari\",\"Mclaren\",\"Mercedes\",\"Redbull\"]\n",
    "\n",
    "def imshow(img):\n",
    "    img=img/2+0.5\n",
    "    npimg=img.numpy()\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.show()\n",
    "dataiter=iter(train_loader)\n",
    "images,labels=dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(\"\".join('%5s' % classes[labels[j]] for j in range(batch_size)))\n",
    "print(images.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Mimarisini Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): #model yapısı class içinde oluşturulur ilk 3 satır pytochda class için temel tanımlamalardır.\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        #conv katmanları:\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=4,kernel_size=(5,5)) #giriş kanalı, çıkış kanalı ve kernel size ı tanımladık atride(adım) gibi tanımlamaları default değerde bıraktık.\n",
    "        self.conv2=nn.Conv2d(in_channels=4,out_channels=8,kernel_size=(3,3))\n",
    "        self.conv3=nn.Conv2d(in_channels=8,out_channels=16,kernel_size=(2,2))\n",
    "        self.conv4=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=(2,2))\n",
    "        #max pooling katmanı:\n",
    "\n",
    "        self.max=nn.MaxPool2d(kernel_size=(2,2)) # bu katman her conv dan sonra çalışıcak bağlama kısmında belirtiyoruz. Buraya birden fazla maxpool fonksiyonu tanımlayıp bağlama fonksiyonunda onlarıda kullanabiliriz.\n",
    "\n",
    "        #aktivasyon fonksiyonu:\n",
    "        self.func=nn.ELU()\n",
    "\n",
    "        #fully connected laerımız: (\"tensorflowda dense diye geçiyor\")\n",
    "        self.fc1=nn.Linear(in_features=32,out_features=50) #conv katmanından en son 32 kanal çıktıgı için girişi 32 ile başlattık.\n",
    "        self.fc2=nn.Linear(in_features=50,out_features=50)\n",
    "        self.fc3=nn.Linear(in_features=50,out_features=100)\n",
    "        self.fc4=nn.Linear(in_features=100,out_features=4) # son çıktı katmanımız 4 formula aracı oldugu için 4 çıkışlı yaptık.\n",
    "\n",
    "    def forward(self,x): # bu fonksiyon bağlama fonksiyonudur oluşturdugumuz katmanlar birbirine bağlı değil bu fonksiyon ile bağlama işlmeini geçekleştiriyoruz.\n",
    "         x=self.conv1(x) #conv katmanının çıkışını aktivasyon fonksiyonuna onuda maxpool a gönderiyoruz sonuncu conv katmanının çıkışında maxpool yok\n",
    "         x=self.func(x)\n",
    "         x=self.max(x)\n",
    "\n",
    "         x=self.conv2(x)\n",
    "         x=self.func(x)\n",
    "         x=self.max(x)\n",
    "\n",
    "         x=self.conv3(x)\n",
    "         x=self.func(x)\n",
    "         x=self.max(x)\n",
    "\n",
    "         x=self.conv4(x)\n",
    "         x=self.func(x)\n",
    "\n",
    "         x=x.view(x.size(0),-1) #flatten: düzleştirme işlemi\n",
    "\n",
    "         x=self.fc1(x)\n",
    "         x=self.func(x)\n",
    "         x=self.fc2(x)\n",
    "         x=self.func(x)\n",
    "         x=self.fc3(x)\n",
    "         x=self.func(x)\n",
    "         x=self.fc4(x)\n",
    "            \n",
    "         return x\n",
    "          \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin Eğitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflowda fit metoduyla yaptıgımız işlem.\n",
    "\n",
    "start=time.time() # zamınımızı tutacak yapmasakta olur\n",
    "\n",
    "model=Net() # yukarda tanımladıgımız classı çağırıyoruz\n",
    "\n",
    "optimizer=torch.optim.Adamax(model.parameters(),lr=0.001) #optimizasyon fonksiyonumuzu belirliyoruz. İçerisine modelimizin parametrelerini ve learning rate değerimizi giriyoruzki ağırlıkları güncelleyebilsin.\n",
    "\n",
    "error=torch.nn.CrossEntropyLoss() #loss fonksiyonumuzu belirledik\n",
    "\n",
    "epoch = 10\n",
    "\n",
    "for j in range(epoch):\n",
    "    for i,(images,label) in enumerate (train_loader):\n",
    "\n",
    "        optimizer.zero_grad() # her bir epoch sonunda türev değerlini sıfırlıyor. Ağırlıklara göre her bir epocta yeni bir türev değeri hesaplıyor.\n",
    "        tahmin=model(images)\n",
    "        loss=error(tahmin,label)\n",
    "        loss.backward() # kayıp değerine göre geri yayılımı uyguluyoruz.\n",
    "        optimizer.step() #zero_grad, backward ve step fonksiyonları olmazla olmaz fonksiyonlar. step sonraki adıma geçmemizi sağlıyor.\n",
    "\n",
    "        print(\"Epoch [{}/{}],loss:{:.4f}\".format(j+1,i+1,loss.item()))\n",
    "end=time.time()\n",
    "print(\"süre:\",end-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dogruluk(loader,model):\n",
    "    num_correct=0\n",
    "    num_samples=0\n",
    "    model.eval()#modeli test edicez\n",
    "\n",
    "    with torch.no_grad(): #burda modelimizi eğitmediğimiz için türevleri hesaplatmıcaz\n",
    "        for x,y in loader:\n",
    "            tahmin=model(x)\n",
    "            _,pred=tahmin.max(1)\n",
    "            num_correct+=(pred==y).sum() #tahmin değerimizi y' ye eşitse correcti 1 artıracak\n",
    "            num_samples+=pred.size(0)\n",
    "            \n",
    "        print(f\"Got {num_correct}/{num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n",
    "        model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train dogruluk:\")\n",
    "dogruluk(train_loader,model)\n",
    "print(\"test dogruluk:\")\n",
    "dogruluk(test_loader,model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin Eğitimi ve Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100 loss: 1.431093454360962 accuracy: 48.10% Error: 51.90%\n",
      "Iteration: 200 loss: 0.9139726758003235 accuracy: 56.96% Error: 43.04%\n",
      "Iteration: 300 loss: 1.1586244106292725 accuracy: 62.03% Error: 37.97%\n",
      "Iteration: 400 loss: 0.09702415019273758 accuracy: 60.76% Error: 39.24%\n",
      "Iteration: 500 loss: 1.006575107574463 accuracy: 62.03% Error: 37.97%\n",
      "Iteration: 600 loss: 0.047033362090587616 accuracy: 58.23% Error: 41.77%\n",
      "Iteration: 700 loss: 1.1262098550796509 accuracy: 65.82% Error: 34.18%\n",
      "Iteration: 800 loss: 0.08997895568609238 accuracy: 62.03% Error: 37.97%\n",
      "Iteration: 900 loss: 0.5614885687828064 accuracy: 77.22% Error: 22.78%\n",
      "Iteration: 1000 loss: 0.08382895588874817 accuracy: 67.09% Error: 32.91%\n",
      "Iteration: 1100 loss: 0.3654977083206177 accuracy: 75.95% Error: 24.05%\n",
      "Iteration: 1200 loss: 0.015043382532894611 accuracy: 60.76% Error: 39.24%\n",
      "Iteration: 1300 loss: 0.2500057816505432 accuracy: 74.68% Error: 25.32%\n",
      "Iteration: 1400 loss: 0.21667613089084625 accuracy: 70.89% Error: 29.11%\n",
      "Iteration: 1500 loss: 0.3522079586982727 accuracy: 77.22% Error: 22.78%\n",
      "Iteration: 1600 loss: 0.012147023342549801 accuracy: 72.15% Error: 27.85%\n",
      "Iteration: 1700 loss: 0.2854798138141632 accuracy: 77.22% Error: 22.78%\n",
      "Iteration: 1800 loss: 0.0041315918788313866 accuracy: 73.42% Error: 26.58%\n",
      "Iteration: 1900 loss: 0.20730015635490417 accuracy: 77.22% Error: 22.78%\n"
     ]
    }
   ],
   "source": [
    "# bu kısımda model eğitilirken aynı zamanda testide yaptıgımız kısımdır. Bu aşamayı kullanırken önceki iki aşamaya gerek kalmıyor.\n",
    "\n",
    "start=time.time() \n",
    "\n",
    "model=Net() \n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001) \n",
    "\n",
    "error=torch.nn.CrossEntropyLoss() \n",
    "\n",
    "epoch = 10\n",
    "\n",
    "kayıp=[] #loss bilgimizi eklicez\n",
    "count=0\n",
    "iterasyon=[] #iterasyonları buna eklicez\n",
    "for i in range(epoch):\n",
    "    for i,(images,label) in enumerate(train_loader):\n",
    "        tahmin=model(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss=error(tahmin,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        count+=1\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            total=0\n",
    "            correct=0\n",
    "            correct_hata=0\n",
    "            for image,labels in test_loader:\n",
    "                out=model(image)\n",
    "                pred=torch.max(out.data,1)[1]\n",
    "                total+=len(label)\n",
    "\n",
    "                correct+=(pred==labels).sum() #doğru sayımız\n",
    "                correct_hata+=(pred!=labels).sum() # yanlış sayımız\n",
    "            dogruluk=100*correct/float(total)\n",
    "            hata=100*correct_hata/float(total)\n",
    "\n",
    "            kayıp.append(loss.data)\n",
    "            iterasyon.append(count)\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            print('Iteration: {} loss: {} accuracy: {:.2f}% Error: {:.2f}%'.format(count,loss.data,dogruluk,hata))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "end=time.time()\n",
    "print(\"süre:\",end-start)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6890cd249af4e4ffbb6e94abfb53100042eb61c81d00e1f1ac790c73285b1fdf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
