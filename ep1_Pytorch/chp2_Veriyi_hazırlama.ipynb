{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from skimage import io\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriyi Dahil Etme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class veri(Dataset): #dataset classı pytorch un veriyi eklemek için kullandırttığı bir classdır.\n",
    "    def __init__(self, csv_file, root_dir, transform=None): #csv_file fotograflarımızın adreslerinin yer aldığı dosyadır onun pathini vermemiz gerekiyor. root_dir fotograflarımızın oldugu klasörün adresidir\n",
    "        self.annotations=pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    def __getitem__(self, index):\n",
    "       img_path=os.path.join(self.root_dir,self.annotations.iloc[index,0])\n",
    "       image=io.imread(img_path)\n",
    "       y_label=torch.tensor(int(self.annotations.iloc[index,1]))\n",
    "       \n",
    "       if self.transform:\n",
    "              image=self.transform(image)\n",
    "              return (image,y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriyi Hazırlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=veri(csv_file=\"D:\\\\udemy_data\\\\f1_classification\\\\f111.csv\",root_dir=\"D:\\\\udemy_data\\\\f1_classification\",\n",
    "transform=torchvision.transforms.Compose([ #compose metodu birden fazla transform işlemini tek seferde yapmamıza olanak tanır.\n",
    "    transforms.ToTensor(), #tensore cevirmemizi sağlar verimizi\n",
    "    transforms.Resize(size=(28,28)),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,test_set=torch.utils.data.random_split(dataset,[200,79]) # verimizin 200 ü train geri kalan 79 tanesi test için ayrıldı\n",
    "train_loader=DataLoader(dataset=train_set,batch_size=1,shuffle=False)\n",
    "test_loader=DataLoader(dataset=test_set,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriyi Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "batch_size=1\n",
    "classes=[\"Ferrari\",\"Mclaren\",\"Mercedes\",\"Redbull\"]\n",
    "\n",
    "def imshow(img):\n",
    "    img=img/2+0.5\n",
    "    npimg=img.numpy()\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.show()\n",
    "dataiter=iter(train_loader)\n",
    "images,labels=dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(\"\".join('%5s' % classes[labels[j]] for j in range(batch_size)))\n",
    "print(images.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Mimarisini Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): #model yapısı class içinde oluşturulur ilk 3 satır pytochda class için temel tanımlamalardır.\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        #conv katmanları:\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=4,kernel_size=(5,5)) #giriş kanalı, çıkış kanalı ve kernel size ı tanımladık atride(adım) gibi tanımlamaları default değerde bıraktık.\n",
    "        self.conv2=nn.Conv2d(in_channels=4,out_channels=8,kernel_size=(3,3))\n",
    "        self.conv3=nn.Conv2d(in_channels=8,out_channels=16,kernel_size=(2,2))\n",
    "        self.conv4=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=(2,2))\n",
    "        #max pooling katmanı:\n",
    "\n",
    "        self.max=nn.MaxPool2d(kernel_size=(2,2)) # bu katman her conv dan sonra çalışıcak bağlama kısmında belirtiyoruz. Buraya birden fazla maxpool fonksiyonu tanımlayıp bağlama fonksiyonunda onlarıda kullanabiliriz.\n",
    "\n",
    "        #aktivasyon fonksiyonu:\n",
    "        self.func=nn.ELU()\n",
    "\n",
    "        #fully connected laerımız: (\"tensorflowda dense diye geçiyor\")\n",
    "        self.fc1=nn.Linear(in_features=32,out_features=50) #conv katmanından en son 32 kanal çıktıgı için girişi 32 ile başlattık.\n",
    "        self.fc2=nn.Linear(in_features=50,out_features=50)\n",
    "        self.fc3=nn.Linear(in_features=50,out_features=100)\n",
    "        self.fc4=nn.Linear(in_features=100,out_features=4) # son çıktı katmanımız 4 formula aracı oldugu için 4 çıkışlı yaptık.\n",
    "\n",
    "    def forward(self,x): # bu fonksiyon bağlama fonksiyonudur oluşturdugumuz katmanlar birbirine bağlı değil bu fonksiyon ile bağlama işlmeini geçekleştiriyoruz.\n",
    "         x=self.conv1(x) #conv katmanının çıkışını aktivasyon fonksiyonuna onuda maxpool a gönderiyoruz sonuncu conv katmanının çıkışında maxpool yok\n",
    "         x=self.func(x)\n",
    "         x=self.max(x)\n",
    "\n",
    "         x=self.conv2(x)\n",
    "         x=self.func(x)\n",
    "         x=self.max(x)\n",
    "\n",
    "         x=self.conv3(x)\n",
    "         x=self.func(x)\n",
    "         x=self.max(x)\n",
    "\n",
    "         x=self.conv4(x)\n",
    "         x=self.func(x)\n",
    "\n",
    "         x=x.view(x.size(0),-1) #flatten: düzleştirme işlemi\n",
    "\n",
    "         x=self.fc1(x)\n",
    "         x=self.func(x)\n",
    "         x=self.fc2(x)\n",
    "         x=self.func(x)\n",
    "         x=self.fc3(x)\n",
    "         x=self.func(x)\n",
    "         x=self.fc4(x)\n",
    "            \n",
    "         return x\n",
    "          \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin Eğitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflowda fit metoduyla yaptıgımız işlem.\n",
    "\n",
    "start=time.time() # zamınımızı tutacak yapmasakta olur\n",
    "\n",
    "model=Net() # yukarda tanımladıgımız classı çağırıyoruz\n",
    "\n",
    "optimizer=torch.optim.Adamax(model.parameters(),lr=0.001) #optimizasyon fonksiyonumuzu belirliyoruz. İçerisine modelimizin parametrelerini ve learning rate değerimizi giriyoruzki ağırlıkları güncelleyebilsin.\n",
    "\n",
    "error=torch.nn.CrossEntropyLoss() #loss fonksiyonumuzu belirledik\n",
    "\n",
    "epoch = 10\n",
    "\n",
    "for j in range(epoch):\n",
    "    for i,(images,label) in enumerate (train_loader):\n",
    "\n",
    "        optimizer.zero_grad() # her bir epoch sonunda türev değerlini sıfırlıyor. Ağırlıklara göre her bir epocta yeni bir türev değeri hesaplıyor.\n",
    "        tahmin=model(images)\n",
    "        loss=error(tahmin,label)\n",
    "        loss.backward() # kayıp değerine göre geri yayılımı uyguluyoruz.\n",
    "        optimizer.step() #zero_grad, backward ve step fonksiyonları olmazla olmaz fonksiyonlar. step sonraki adıma geçmemizi sağlıyor.\n",
    "\n",
    "        print(\"Epoch [{}/{}],loss:{:.4f}\".format(j+1,i+1,loss.item()))\n",
    "end=time.time()\n",
    "print(\"süre:\",end-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dogruluk(loader,model):\n",
    "    num_correct=0\n",
    "    num_samples=0\n",
    "    model.eval()#modeli test edicez\n",
    "\n",
    "    with torch.no_grad(): #burda modelimizi eğitmediğimiz için türevleri hesaplatmıcaz\n",
    "        for x,y in loader:\n",
    "            tahmin=model(x)\n",
    "            _,pred=tahmin.max(1)\n",
    "            num_correct+=(pred==y).sum() #tahmin değerimizi y' ye eşitse correcti 1 artıracak\n",
    "            num_samples+=pred.size(0)\n",
    "            \n",
    "        print(f\"Got {num_correct}/{num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n",
    "        model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train dogruluk:\")\n",
    "dogruluk(train_loader,model)\n",
    "print(\"test dogruluk:\")\n",
    "dogruluk(test_loader,model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelin Eğitimi ve Testi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bu kısımda model eğitilirken aynı zamanda testide yaptıgımız kısımdır. Bu aşamayı kullanırken önceki iki aşamaya gerek kalmıyor.\n",
    "\n",
    "start=time.time() \n",
    "\n",
    "model=Net() \n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001) \n",
    "\n",
    "error=torch.nn.CrossEntropyLoss() \n",
    "\n",
    "epoch = 10\n",
    "\n",
    "kayıp=[] #loss bilgimizi eklicez\n",
    "count=0\n",
    "iterasyon=[] #iterasyonları buna eklicez\n",
    "for i in range(epoch):\n",
    "    for i,(images,label) in enumerate(train_loader):\n",
    "        tahmin=model(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss=error(tahmin,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        count+=1\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            total=0\n",
    "            correct=0\n",
    "            correct_hata=0\n",
    "            for image,labels in test_loader:\n",
    "                out=model(image)\n",
    "                pred=torch.max(out.data,1)[1]\n",
    "                total+=len(label)\n",
    "\n",
    "                correct+=(pred==labels).sum() #doğru sayımız\n",
    "                correct_hata+=(pred!=labels).sum() # yanlış sayımız\n",
    "            dogruluk=100*correct/float(total)\n",
    "            hata=100*correct_hata/float(total)\n",
    "\n",
    "            kayıp.append(loss.data)\n",
    "            iterasyon.append(count)\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            print('Iteration: {} loss: {} accuracy: {:.2f}% Error: {:.2f}%'.format(count,loss.data,dogruluk,hata))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "end=time.time()\n",
    "print(\"süre:\",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"udemy1.pth\") #modeli kaydetme\n",
    "torch.save(model.state_dict(),\"udemy11.pth\") #modelin sadece ağırlıklarını kaydetme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=torch.load(\"udemy1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model11=Net() #ağırlıkları kullanarak laod etme (tekrar classımızı çağırıp eval ile modeli çağırıyoruz)\n",
    "model11.load_state_dict(torch.load(\"udemy11.pth\"))\n",
    "model11.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train dogruluk:\")\n",
    "dogruluk(train_loader,model1)\n",
    "print(\"test dogruluk:\")\n",
    "dogruluk(test_loader,model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary(Özet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model,input_size=(3,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"loss graph\")\n",
    "plt.plot(iterasyon,kayıp,\"-o\",color=\"g\")\n",
    "\n",
    "plt.xlabel=(\"iterasyon\")\n",
    "plt.ylabel=(\"loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6890cd249af4e4ffbb6e94abfb53100042eb61c81d00e1f1ac790c73285b1fdf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
